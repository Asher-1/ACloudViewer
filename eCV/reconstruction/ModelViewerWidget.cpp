// Copyright (c) 2018, ETH Zurich and UNC Chapel Hill.
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//
//     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of
//       its contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
//
// Author: Johannes L. Schoenberger (jsch-at-demuc-dot-de)

#include "ModelViewerWidget.h"

#include "QtUtils.h"
#include "ReconstructionWidget.h"
#include "RenderOptions.h"

// CV_DB_LIB
#include <ecvCameraSensor.h>
#include <ecvDisplayTools.h>
#include <ecvHObjectCaster.h>
#include <ecvPointCloud.h>

// LOCAL
#include "MainWindow.h"
#include "ecvDBRoot.h"
#include "ecvConsole.h"

#define SELECTION_BUFFER_IMAGE_IDX 0
#define SELECTION_BUFFER_POINT_IDX 1

const Eigen::Vector4d kSelectedPointColor(0.0, 1.0, 0.0, 1.0);

const Eigen::Vector4d kSelectedImagePlaneColor(1.0, 0.0, 1.0, 0.6);
const Eigen::Vector4d kSelectedImageFrameColor(0.8, 0.0, 0.8, 1.0);

const Eigen::Vector4d kMovieGrabberImagePlaneColor(0.0, 1.0, 1.0, 0.6);
const Eigen::Vector4d kMovieGrabberImageFrameColor(0.0, 0.8, 0.8, 1.0);

namespace cloudViewer {
namespace {

// Generate unique index from RGB color in the range [0, 256^3].
inline size_t RGBToIndex(const uint8_t r, const uint8_t g, const uint8_t b) {
    return static_cast<size_t>(r) + static_cast<size_t>(g) * 256 +
           static_cast<size_t>(b) * 65536;
}

// Derive color from unique index, generated by `RGBToIndex`.
inline Eigen::Vector4f IndexToRGB(const size_t index) {
    Eigen::Vector4f color;
    color(0) = ((index & 0x000000FF) >> 0) / 255.0f;
    color(1) = ((index & 0x0000FF00) >> 8) / 255.0f;
    color(2) = ((index & 0x00FF0000) >> 16) / 255.0f;
    color(3) = 1.0f;
    return color;
}

void BuildImageModel(ccCameraSensor* sensor,
                     const colmap::Image& image,
                     const colmap::Camera& camera,
                     const float image_size,
                     const Eigen::Vector4d& plane_color,
                     const Eigen::Vector4d& frame_color) {
    // temp information
    const float kBaseCameraWidth = 1024.0f;
    const float image_width = image_size * camera.Width() / kBaseCameraWidth;
    const float image_height = image_width *
                               static_cast<float>(camera.Height()) /
                               static_cast<float>(camera.Width());
    const float image_extent = std::max(image_width, image_height);
    const float camera_extent = std::max(camera.Width(), camera.Height());
    const float camera_extent_world =
            static_cast<float>(camera.ImageToWorldThreshold(camera_extent));
    const float focal_length = 2.0f * image_extent / camera_extent_world;

    // set color
    ecvColor::Rgb planeColor = ecvColor::Rgb::FromEigen(
            Eigen::Vector3d(plane_color(0), plane_color(1), plane_color(2)));
    sensor->setPlaneColor(planeColor);
    ecvColor::Rgb frameColor = ecvColor::Rgb::FromEigen(
            Eigen::Vector3d(frame_color(0), frame_color(1), frame_color(2)));
    sensor->setFrameColor(frameColor);
    int retinaScale = ecvDisplayTools::GetDevicePixelRatio();
    sensor->setGraphicScale(-PC_ONE / retinaScale);

    // init camera intrinsic parameters
    ccCameraSensor::IntrinsicParameters iParams;
    iParams.zFar_mm = 1e5f;
    iParams.zNear_mm = 1e-3f;
    float pixelSize_mm = image_size;  // pixel size (real distance in meter)
    iParams.pixelSize_mm[0] = pixelSize_mm;
    iParams.pixelSize_mm[1] = pixelSize_mm;
    iParams.vertFocal_pix =
            ccCameraSensor::ConvertFocalMMToPix(focal_length, pixelSize_mm);
    iParams.vFOV_rad = cloudViewer::DegreesToRadians(45.0f);
    iParams.arrayWidth = static_cast<int>(camera.Width());
    iParams.arrayHeight = static_cast<int>(camera.Height());
    iParams.principal_point[0] = static_cast<float>(camera.PrincipalPointX());
    iParams.principal_point[1] = static_cast<float>(camera.PrincipalPointY());
    sensor->setIntrinsicParameters(iParams);

    // init camera rigid transformation parameters
    const Eigen::Matrix<float, 3, 4> proj_matrix =
            image.InverseProjectionMatrix().cast<float>();
    Eigen::Matrix3f rotation = proj_matrix.leftCols<3>();
    Eigen::Vector3f translation = proj_matrix.rightCols<1>();
    ccGLMatrix rot = ccGLMatrix::FromEigenMatrix3(rotation);
    rot.setTranslation(translation.data());
    sensor->setRigidTransformation(rot);
}

}  // namespace

using namespace colmap;
ModelViewerWidget::ModelViewerWidget(QWidget* parent,
                                     OptionManager* options,
                                     MainWindow* app)
    : QWidget(parent),
      statusbar_status_label(nullptr),
      options_(options),
      point_viewer_widget_(new PointViewerWidget(parent, this, options)),
      image_viewer_widget_(
              new DatabaseImageViewerWidget(parent, this, options)),
      movie_grabber_widget_(new MovieGrabberWidget(parent, this)),
      focus_distance_(kInitFocusDistance),
      selected_image_id_(kInvalidImageId),
      selected_point3D_id_(kInvalidPoint3DId),
      app_(app),
      cloud_sparse_(nullptr),
      main_sensors_(nullptr) {
    SetupView();
    SetPointColormap(new PointColormapPhotometric());
    SetImageColormap(new ImageColormapUniform());

    connect(ecvDisplayTools::TheInstance(), &ecvDisplayTools::itemPicked, this,
            &ModelViewerWidget::SelectObject);

    image_size_ = static_cast<float>(ecvDisplayTools::GetDevicePixelRatio() *
                                     image_size_);
    point_size_ = static_cast<float>(ecvDisplayTools::GetDevicePixelRatio() *
                                     point_size_);

    point_line_data_.clear();
    image_line_data_.clear();
    sensors_.clear();
    movie_grabber_sensors_.clear();
}

void ModelViewerWidget::Release() {
    if (movie_grabber_widget_) {
        movie_grabber_widget_->views.clear();
    }

    ClearReconstruction();

    if (cloud_sparse_) {
        delete cloud_sparse_;
        cloud_sparse_ = nullptr;
    }

    if (main_sensors_) {
        delete main_sensors_;
        main_sensors_ = nullptr;
    }
}

QWidget* ModelViewerWidget::getMainWindow() { return app_; }

void ModelViewerWidget::ReloadReconstruction() {
    if (reconstruction == nullptr) {
        return;
    }

    cameras = reconstruction->Cameras();
    points3D = reconstruction->Points3D();
    reg_image_ids = reconstruction->RegImageIds();

    images.clear();
    for (const image_t image_id : reg_image_ids) {
        images[image_id] = reconstruction->Image(image_id);
    }

    if (statusbar_status_label) {
        statusbar_status_label->setText(QString().asprintf(
                "%d Images - %d Points", static_cast<int>(reg_image_ids.size()),
                static_cast<int>(points3D.size())));
    }

    Upload();
}

void ModelViewerWidget::ClearReconstruction() {
    cameras.clear();
    images.clear();
    points3D.clear();
    reg_image_ids.clear();
    reconstruction = nullptr;
    selected_image_id_ = kInvalidImageId;
    selected_point3D_id_ = kInvalidPoint3DId;
    Upload();
}

int ModelViewerWidget::GetProjectionType() const {
    if (ecvDisplayTools::GetPerspectiveState()) {
        options_->render->projection_type =
                RenderOptions::ProjectionType::PERSPECTIVE;
    } else {
        options_->render->projection_type =
                RenderOptions::ProjectionType::ORTHOGRAPHIC;
    }
    return options_->render->projection_type;
}

void ModelViewerWidget::SetPointColormap(PointColormapBase* colormap) {
    point_colormap_.reset(colormap);
}

void ModelViewerWidget::SetImageColormap(ImageColormapBase* colormap) {
    image_colormap_.reset(colormap);
}

void ModelViewerWidget::UpdateMovieGrabber() {
    StartRender();
    UploadMovieGrabberData();
    EndRender(false);
    update();
}

float ModelViewerWidget::ZoomScale() {
    focus_distance_ =
            static_cast<float>(ecvDisplayTools::GetCameraFocalDistance());
    // "Constant" scale factor w.r.t. zoom-level.
    return 2.0f *
           std::tan(static_cast<float>(DegToRad(ecvDisplayTools::GetFov())) /
                    2.0f) *
           std::abs(focus_distance_) / ecvDisplayTools::GlHeight();
}

float ModelViewerWidget::AspectRatio() const {
    return static_cast<float>(ecvDisplayTools::GlWidth()) /
           static_cast<float>(ecvDisplayTools::GlHeight());
}

void ModelViewerWidget::ChangeFocusDistance(const float delta) {
    if (delta == 0.0f) {
        return;
    }

    focus_distance_ =
            static_cast<float>(ecvDisplayTools::GetCameraFocalDistance());
    const float prev_focus_distance = focus_distance_;
    float diff = delta * ZoomScale() * kFocusSpeed;
    focus_distance_ -= diff;
    if (focus_distance_ < kMinFocusDistance) {
        focus_distance_ = kMinFocusDistance;
        diff = prev_focus_distance - focus_distance_;
    } else if (focus_distance_ > kMaxFocusDistance) {
        focus_distance_ = kMaxFocusDistance;
        diff = prev_focus_distance - focus_distance_;
    }
    ecvDisplayTools::SetCameraFocalDistance(
            static_cast<double>(focus_distance_));
    ecvDisplayTools::Update();
}

void ModelViewerWidget::ChangePointSize(const float delta) {
    if (delta == 0.0f) {
        return;
    }
    point_size_ *= (1.0f + delta / 100.0f * kPointScaleSpeed);
    point_size_ = std::max(kMinPointSize, std::min(kMaxPointSize, point_size_));

    StartRender();
    if (cloud_sparse_) {
        cloud_sparse_->setPointSize(static_cast<unsigned>(point_size_));
    }
    EndRender(false);
    update();
}

void ModelViewerWidget::ChangeCameraSize(const float delta) {
    if (delta == 0.0f) {
        return;
    }
    image_size_ *= (1.0f + delta / 100.0f * kImageScaleSpeed);
    image_size_ = std::max(kMinImageSize, std::min(kMaxImageSize, image_size_));
    StartRender();
    UploadImageData();
    UploadMovieGrabberData();
    EndRender(false);
    update();
}

void ModelViewerWidget::ResetView() {
    SetupView();
    Upload();
}

ccGLMatrixd ModelViewerWidget::ModelViewMatrix() const {
    ccGLMatrixd mat;
    ecvDisplayTools::GetViewMatrix(mat.data());
    return mat;
}

void ModelViewerWidget::SelectObject(ccHObject* entity,
                                     unsigned subEntityID,
                                     int x,
                                     int y,
                                     const CCVector3& P) {
    Q_UNUSED(x);
    Q_UNUSED(y);

    if (!entity || reg_image_ids.empty() || points3D.empty()) {
        return;
    }

    ccHObject* obj = entity;
    if (!main_sensors_ || !cloud_sparse_) {
        return;
    } else {
        if (obj->isKindOf(CV_TYPES::CAMERA_SENSOR)) {
            if (!main_sensors_->find(subEntityID)) {
                return;
            }
        } else if (obj->isKindOf(CV_TYPES::POINT_CLOUD)) {
            if (cloud_sparse_->getUniqueID() != obj->getUniqueID()) {
                return;
            }
        }
    }

    // Upload data in selection mode (one color per object).
    UploadImageData(true);
    UploadPointData(true);

    std::size_t selected_index = 0;
    if (obj->isKindOf(CV_TYPES::CAMERA_SENSOR)) {
        ccCameraSensor* camera = ccHObjectCaster::ToCameraSensor(obj);
        ecvColor::Rgb plane_color = camera->getPlaneColor();
        selected_index =
                RGBToIndex(plane_color.r, plane_color.g, plane_color.b);
    } else if (obj->isKindOf(CV_TYPES::POINT_CLOUD) &&
               obj->getUniqueID() == cloud_sparse_->getUniqueID()) {
        selected_index = static_cast<std::size_t>(subEntityID);
        if (selected_index >= cloud_sparse_->size()) {
            CVLog::Warning(
                    "[ModelViewerWidget::SelectObject] Invalid picking point "
                    "index!");
            return;
        }

        const CCVector3* refP = cloud_sparse_->getPointPtr(selected_index);
        if (GreaterThanEpsilon((P - *refP).norm())) {
            return;
        }

        ecvColor::Rgb& pointColor =
                cloud_sparse_->getPointColorPtr(selected_index);
        selected_index = RGBToIndex(pointColor.r, pointColor.g, pointColor.b);

    } else {
        return;
    }

    colmap::image_t last_selected_image_id = selected_image_id_;

    if (selected_index < selection_buffer_.size()) {
        const char buffer_type = selection_buffer_[selected_index].second;
        if (buffer_type == SELECTION_BUFFER_IMAGE_IDX) {
            selected_image_id_ = static_cast<image_t>(
                    selection_buffer_[selected_index].first);
            selected_point3D_id_ = kInvalidPoint3DId;
            ShowImageInfo(selected_image_id_);
        } else if (buffer_type == SELECTION_BUFFER_POINT_IDX) {
            selected_image_id_ = kInvalidImageId;
            selected_point3D_id_ = selection_buffer_[selected_index].first;
            ShowPointInfo(selection_buffer_[selected_index].first);
        } else {
            selected_image_id_ = kInvalidImageId;
            selected_point3D_id_ = kInvalidPoint3DId;
            image_viewer_widget_->hide();
        }
    } else {
        selected_image_id_ = kInvalidImageId;
        selected_point3D_id_ = kInvalidPoint3DId;
        image_viewer_widget_->hide();
    }

    selection_buffer_.clear();

    StartRender();
    UploadPointData();
    UploadImageData();
    UploadPointConnectionData();
    UploadImageConnectionData();
    EndRender(false);

    if (app_) {
        if (selected_image_id_ == kInvalidImageId) {
            app_->db()->expandElement(main_sensors_, false);
            ccHObject* obj = getSelectedCamera(last_selected_image_id);
            if (obj) {
                app_->db()->unselectEntity(obj);
            }
        } else {
            app_->db()->expandElement(main_sensors_, true);
            ccHObject* obj = getSelectedCamera(selected_image_id_);
            if (obj) {
                app_->db()->selectEntity(obj);
            }
        }
    }

    update();
}

void ModelViewerWidget::SelectMoviewGrabberView(const size_t view_idx) {
    selected_movie_grabber_view_ = view_idx;
    StartRender();
    UploadMovieGrabberData();
    EndRender(false);
    update();
}

QImage ModelViewerWidget::GrabImage() {
    // render to image
    return ecvDisplayTools::RenderToImage(1, false, true, 0);
}

void ModelViewerWidget::GrabMovie() {
    if (GetProjectionType() != RenderOptions::ProjectionType::PERSPECTIVE) {
        const int reply = QMessageBox::question(
                this, tr("Warning"),
                tr("You must use perspective projection, "
                   "do you want to switch to perspective mode now?"),
                QMessageBox::Yes | QMessageBox::No);
        if (reply == QMessageBox::Yes) {
            if (app_) {
                app_->doActionPerspectiveProjection();
            }
        } else {
            return;
        }
    }

    movie_grabber_widget_->show();
}

void ModelViewerWidget::ShowPointInfo(const point3D_t point3D_id) {
    point_viewer_widget_->Show(point3D_id);
}

void ModelViewerWidget::ShowImageInfo(const image_t image_id) {
    image_viewer_widget_->ShowImageWithId(image_id);
}

void ModelViewerWidget::SetPerspectiveProjection() {
    if (app_) {
        app_->doActionPerspectiveProjection();
    }
}

void ModelViewerWidget::SetOrthogonalProjection() {
    if (app_) {
        app_->doActionOrthogonalProjection();
    }
}

float ModelViewerWidget::PointSize() const { return point_size_; }

float ModelViewerWidget::ImageSize() const { return image_size_; }

void ModelViewerWidget::SetPointSize(const float point_size,
                                     bool autoUpdate /* = true*/) {
    point_size_ = point_size;

    if (autoUpdate) {
        StartRender();
    }

    if (cloud_sparse_) {
        cloud_sparse_->setPointSize(static_cast<unsigned>(point_size_));
    }

    if (autoUpdate) {
        EndRender(false);
        update();
    }
}

void ModelViewerWidget::SetImageSize(const float image_size,
                                     bool autoUpdate /* = true*/) {
    image_size_ = image_size;

    if (autoUpdate) {
        StartRender();
    }

    UploadImageData();

    if (autoUpdate) {
        EndRender(false);
        update();
    }
}

void ModelViewerWidget::SetBackgroundColor(const float r,
                                           const float g,
                                           const float b) {
    ecvGui::ParamStruct params = ecvGui::Parameters();
    params.backgroundCol =
            ecvColor::Rgb::FromEigen(Eigen::Vector3f(r, g, b).cast<double>());
    ecvDisplayTools::SetDisplayParameters(params);
    ecvDisplayTools::RedrawDisplay(true, false);
}

void ModelViewerWidget::SetupView() {
    point_size_ = kInitPointSize;
    image_size_ = kInitImageSize;
    focus_distance_ = kInitFocusDistance;
}

void ModelViewerWidget::Upload() {
    point_colormap_->Prepare(cameras, images, points3D, reg_image_ids);
    image_colormap_->Prepare(cameras, images, points3D, reg_image_ids);

    StartRender();
    UploadPointData();
    UploadImageData();
    UploadMovieGrabberData();
    UploadPointConnectionData();
    UploadImageConnectionData();
    EndRender();

    update();
}

void ModelViewerWidget::StartRender() {
    // render before
    ecvDisplayTools::SetRedrawRecursive(false);
    bbox_.clear();
}

void ModelViewerWidget::EndRender(bool autoZoom /* = true*/) {
    if (autoZoom && bbox_.isValid()) {
        ecvDisplayTools::UpdateConstellationCenterAndZoom(&bbox_, true);
    } else {
        ecvDisplayTools::RedrawDisplay();
    }
}

void ModelViewerWidget::UploadPointData(const bool selection_mode) {
    if (!cloud_sparse_) {
        cloud_sparse_ = new ccPointCloud("sparseCloud");
        if (!cloud_sparse_) {
            CVLog::Warning(
                    "[ModelViewerWidget::UploadPointData] Not enough memory!");
            return;
        }
    }

    cloud_sparse_->clear();

    if (points3D.size() == 0) {
        resetPointCloud(cloud_sparse_);
        return;
    }

    MainWindow::ccHObjectContext objContext;
    if (app_ &&
        app_->db()->find(static_cast<int>(cloud_sparse_->getUniqueID()))) {
        objContext = app_->removeObjectTemporarilyFromDBTree(cloud_sparse_);
    }

    // Assume we want to display the majority of points
    if (!cloud_sparse_->reserve(static_cast<unsigned>(points3D.size()))) {
        return;
    } else {
        cloud_sparse_->reserveTheRGBTable();
        cloud_sparse_->showColors(true);
    }

    const size_t min_track_len =
            static_cast<size_t>(options_->render->min_track_len);

    if (selected_image_id_ == kInvalidImageId &&
        images.count(selected_image_id_) == 0) {
        for (const auto& point3D : points3D) {
            if (point3D.second.Error() <= options_->render->max_error &&
                point3D.second.Track().Length() >= min_track_len) {
                CCVector3 painter_point;
                painter_point.x =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(0));
                painter_point.y =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(1));
                painter_point.z =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(2));
                cloud_sparse_->addPoint(painter_point);

                Eigen::Vector4d color;
                if (selection_mode) {
                    const size_t index = selection_buffer_.size();
                    selection_buffer_.push_back(std::make_pair(
                            point3D.first, SELECTION_BUFFER_POINT_IDX));
                    color = IndexToRGB(index).cast<double>();

                } else if (point3D.first == selected_point3D_id_) {
                    color = kSelectedPointColor;
                } else {
                    color = point_colormap_
                                    ->ComputeColor(point3D.first,
                                                   point3D.second)
                                    .cast<double>();
                }

                ecvColor::Rgb pointColor = ecvColor::Rgb::FromEigen(
                        Eigen::Vector3d(color(0), color(1), color(2)));
                cloud_sparse_->addRGBColor(pointColor);
            }
        }
    } else {  // Image selected
        const auto& selected_image = images[selected_image_id_];
        for (const auto& point3D : points3D) {
            if (point3D.second.Error() <= options_->render->max_error &&
                point3D.second.Track().Length() >= min_track_len) {
                CCVector3 painter_point;
                painter_point.x =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(0));
                painter_point.y =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(1));
                painter_point.z =
                        static_cast<PointCoordinateType>(point3D.second.XYZ(2));
                cloud_sparse_->addPoint(painter_point);

                Eigen::Vector4d color;
                if (selection_mode) {
                    const size_t index = selection_buffer_.size();
                    selection_buffer_.push_back(std::make_pair(
                            point3D.first, SELECTION_BUFFER_POINT_IDX));
                    color = IndexToRGB(index).cast<double>();
                } else if (selected_image.HasPoint3D(point3D.first)) {
                    color = kSelectedImagePlaneColor;
                } else if (point3D.first == selected_point3D_id_) {
                    color = kSelectedPointColor;
                } else {
                    color = point_colormap_
                                    ->ComputeColor(point3D.first,
                                                   point3D.second)
                                    .cast<double>();
                }

                ecvColor::Rgb pointColor = ecvColor::Rgb::FromEigen(
                        Eigen::Vector3d(color(0), color(1), color(2)));
                cloud_sparse_->addRGBColor(pointColor);
            }
        }
    }

    if (app_ && objContext.parent) {
        app_->putObjectBackIntoDBTree(cloud_sparse_, objContext);
    }

    drawPointCloud(cloud_sparse_);
}

void ModelViewerWidget::UploadPointConnectionData() {
    point_line_data_.clear();
    if (selected_point3D_id_ == kInvalidPoint3DId) {
        // No point selected, so upload empty data
        resetLines(point_line_data_);
        return;
    }

    const auto& point3D = points3D[selected_point3D_id_];
    if (point3D.Track().Elements().empty()) {
        resetLines(point_line_data_);
        return;
    }

    // 3D point position.
    point_line_data_.points_.push_back(point3D.XYZ());

    // All images in which 3D point is observed.
    int index = 0;
    for (const auto& track_el : point3D.Track().Elements()) {
        const Image& conn_image = images[track_el.image_id];
        const Eigen::Vector3d conn_proj_center = conn_image.ProjectionCenter();
        point_line_data_.points_.push_back(conn_proj_center);
        point_line_data_.lines_.push_back(Eigen::Vector2i(0, ++index));
    }

    point_line_data_.paintUniformColor(Eigen::Vector3d(kSelectedPointColor(0),
                                                       kSelectedPointColor(1),
                                                       kSelectedPointColor(2)));
    drawLines(point_line_data_);
}

void ModelViewerWidget::UploadImageData(const bool selection_mode) {
    std::size_t lastSensorNum = sensors_.size();
    std::size_t curSensorNum = reg_image_ids.size();

    if (curSensorNum == 0) {
        resetCameraSensors(sensors_);
        return;
    }

    if (lastSensorNum < curSensorNum) {
        sensors_.reserve(curSensorNum);
    } else if (lastSensorNum > curSensorNum) {
        updateSensors(sensors_, reg_image_ids);
        lastSensorNum = sensors_.size();
    }

    std::size_t cameraIndex = 0;
    for (const image_t image_id : reg_image_ids) {
        const Image& image = images[image_id];
        const Camera& camera = cameras[image.CameraId()];

        Eigen::Vector4f plane_color;
        Eigen::Vector4f frame_color;
        if (selection_mode) {
            const size_t index = selection_buffer_.size();
            selection_buffer_.push_back(
                    std::make_pair(image_id, SELECTION_BUFFER_IMAGE_IDX));
            plane_color = frame_color = IndexToRGB(index);
        } else {
            if (image_id == selected_image_id_) {
                plane_color = kSelectedImagePlaneColor.cast<float>();
                frame_color = kSelectedImageFrameColor.cast<float>();
            } else {
                image_colormap_->ComputeColor(image, &plane_color,
                                              &frame_color);
            }
        }

        // Lines are not colored with the indexed color in selection mode, so do
        // not show them, so they do not block the selection process
        ccCameraSensor* sensor = nullptr;
        if (cameraIndex < lastSensorNum) {
            sensor = sensors_[cameraIndex];
        } else {
            sensor = new ccCameraSensor();
            sensors_.push_back(sensor);
        }

        if (!sensor) {
            return;
        }

        sensor->setName(QString::number(image_id));
        BuildImageModel(sensor, image, camera, image_size_,
                        plane_color.cast<double>(), frame_color.cast<double>());
        cameraIndex++;
    }

    drawCameraSensors(sensors_);
}

void ModelViewerWidget::UploadImageConnectionData() {
    std::vector<image_t> image_ids;

    image_line_data_.clear();

    if (selected_image_id_ != kInvalidImageId) {
        // Show connections to selected images
        image_ids.push_back(selected_image_id_);
    } else if (options_->render->image_connections) {
        // Show all connections
        image_ids = reg_image_ids;
    } else {  // Disabled, so upload empty data
        resetLines(image_line_data_);
        return;
    }

    for (const image_t image_id : image_ids) {
        const Image& image = images.at(image_id);

        const Eigen::Vector3d proj_center = image.ProjectionCenter();

        // Collect all connected images
        std::unordered_set<image_t> conn_image_ids;

        for (const Point2D& point2D : image.Points2D()) {
            if (point2D.HasPoint3D()) {
                const Point3D& point3D = points3D[point2D.Point3DId()];
                for (const auto& track_elem : point3D.Track().Elements()) {
                    conn_image_ids.insert(track_elem.image_id);
                }
            }
        }

        // Selected image in the center.
        int centerIndex = static_cast<int>(image_line_data_.points_.size());
        image_line_data_.points_.push_back(proj_center);

        // All connected images to the selected image.
        int index = centerIndex;
        for (const image_t conn_image_id : conn_image_ids) {
            const Image& conn_image = images[conn_image_id];
            const Eigen::Vector3d conn_proj_center =
                    conn_image.ProjectionCenter();
            image_line_data_.points_.push_back(conn_proj_center);
            image_line_data_.lines_.push_back(
                    Eigen::Vector2i(centerIndex, ++index));
        }
    }

    image_line_data_.paintUniformColor(Eigen::Vector3d(
            kSelectedImageFrameColor(0), kSelectedImageFrameColor(1),
            kSelectedImageFrameColor(2)));
    drawLines(image_line_data_);
}

void ModelViewerWidget::UploadMovieGrabberData() {
    std::size_t lastSensorNum = movie_grabber_sensors_.size();
    std::size_t curSensorNum = movie_grabber_widget_->views.size();

    if (lastSensorNum < curSensorNum) {
        movie_grabber_sensors_.reserve(curSensorNum);
    } else if (lastSensorNum > curSensorNum) {
        std::vector<colmap::image_t> image_ids;
        for (const Image& image : movie_grabber_widget_->views) {
            image_ids.push_back(image.ImageId());
        }
        updateSensors(movie_grabber_sensors_, image_ids);
        lastSensorNum = movie_grabber_sensors_.size();
    }

    movie_grabber_path_.clear();

    if (curSensorNum > 0) {
        const Image& image0 = movie_grabber_widget_->views[0];
        Eigen::Vector3d prev_proj_center = image0.ProjectionCenter();

        for (size_t i = 1; i < movie_grabber_widget_->views.size(); ++i) {
            const Image& image = movie_grabber_widget_->views[i];
            const Eigen::Vector3d curr_proj_center = image.ProjectionCenter();
            movie_grabber_path_.points_.push_back(prev_proj_center);
            movie_grabber_path_.points_.push_back(curr_proj_center);
            std::size_t start = movie_grabber_path_.points_.size() - 2;
            std::size_t end = movie_grabber_path_.points_.size() - 1;
            movie_grabber_path_.lines_.push_back(Eigen::Vector2i(start, end));
            prev_proj_center = curr_proj_center;
        }
        movie_grabber_path_.paintUniformColor(Eigen::Vector3d(
                kSelectedImageFrameColor(0), kSelectedImageFrameColor(1),
                kSelectedImageFrameColor(2)));

        // Setup dummy camera with same settings as current OpenGL viewpoint.
        const unsigned long kDefaultImageWdith = 2048;
        const unsigned long kDefaultImageHeight = 1536;
        const double focal_length =
                -2.0 *
                std::tan(DegToRad(ecvDisplayTools::GetCameraFovy()) / 2.0) *
                kDefaultImageWdith;
        Camera camera;
        camera.InitializeWithId(SimplePinholeCameraModel::model_id,
                                focal_length, kDefaultImageWdith,
                                kDefaultImageHeight);

        // Build all camera models
        std::size_t index = 0;
        for (size_t i = 0; i < curSensorNum; ++i) {
            const Image& image = movie_grabber_widget_->views[i];
            Eigen::Vector4d plane_color;
            Eigen::Vector4d frame_color;
            if (i == selected_movie_grabber_view_) {
                plane_color = kSelectedImagePlaneColor;
                frame_color = kSelectedImageFrameColor;
            } else {
                plane_color = kMovieGrabberImagePlaneColor;
                frame_color = kMovieGrabberImageFrameColor;
            }

            ccCameraSensor* sensor = nullptr;
            if (index < lastSensorNum) {
                sensor = movie_grabber_sensors_[index];
            } else {
                sensor = new ccCameraSensor();
                movie_grabber_sensors_.push_back(sensor);
            }

            if (!sensor) {
                return;
            }

            sensor->setName(QString::number(image.ImageId()));
            BuildImageModel(sensor, image, camera, image_size_, plane_color,
                            frame_color);
            index++;
        }

        drawLines(movie_grabber_path_);
        drawCameraSensors(movie_grabber_sensors_);
    } else {
        resetLines(movie_grabber_path_);
        resetCameraSensors(movie_grabber_sensors_);
        return;
    }
}

void ModelViewerWidget::update() { ecvDisplayTools::UpdateScreen(); }

void ModelViewerWidget::drawPointCloud(ccPointCloud* cloud) {
    if (cloud->isEmpty()) {
        cloud->setVisible(false);
        cloud->setEnabled(false);
        cloud->setRedrawFlagRecursive(false);
        return;
    } else {
        if (app_ && !app_->db()->find(static_cast<int>(cloud->getUniqueID()))) {
            app_->addToDB(cloud);
            cloud->setLocked(true);
        }

        cloud->setPointSize(static_cast<unsigned>(point_size_));
        cloud->setVisible(true);
        cloud->setEnabled(true);
        cloud->setRedrawFlagRecursive(true);
        ccBBox box = cloud->getOwnBB();
        if (box.isValid()) {
            bbox_ += box;
        }
    }
}

void ModelViewerWidget::resetPointCloud(ccPointCloud* cloud) {
    if (cloud) {
        cloud->clear();
        if (app_ && app_->db()->find(cloud->getUniqueID())) {
            cloud->setLocked(false);
            app_->removeFromDB(cloud, false);
        }
    }
}

void ModelViewerWidget::drawLines(geometry::LineSet& lineset) {
    if (!lineset.isEmpty()) {
        CC_DRAW_CONTEXT context;
        if (lineset.isColorOverridden()) {
            context.defaultPolylineColor = lineset.getTempColor();
        } else if (lineset.colorsShown() && lineset.hasColors()) {
            context.defaultPolylineColor =
                    ecvColor::Rgb::FromEigen(lineset.colors_[0]);
        }

        context.currentLineWidth = 1;
        context.viewID = QString::number(lineset.getUniqueID(), 10);
        lineset.setRedrawFlagRecursive(true);
        ccBBox box = lineset.getOwnBB();
        if (box.isValid()) {
            bbox_ += box;
        }

        ecvDisplayTools::Draw(context, &lineset);
    }
}

void ModelViewerWidget::resetLines(geometry::LineSet& lineset) {
    ecvDisplayTools::RemoveEntities(&lineset);
}

void ModelViewerWidget::drawCameraSensors(
        std::vector<ccCameraSensor*>& sensors) {
    if (!main_sensors_) {
        main_sensors_ = new ccHObject("SensorsGroup");
        main_sensors_->setLocked(true);
    }

    MainWindow::ccHObjectContext objContext;
    if (main_sensors_ && app_ &&
        app_->db()->find(static_cast<int>(main_sensors_->getUniqueID()))) {
        objContext = app_->removeObjectTemporarilyFromDBTree(main_sensors_);
    }

    for (std::size_t i = 0; i < sensors.size(); ++i) {
        if (!sensors[i]) continue;
        if (main_sensors_ && !main_sensors_->find(sensors[i]->getUniqueID())) {
            sensors[i]->setLocked(true);
            main_sensors_->addChild(sensors[i]);
        }
        sensors[i]->setVisible(true);
        sensors[i]->setEnabled(true);
        sensors[i]->setRedrawFlagRecursive(true);
        ccBBox box = sensors[i]->getOwnBB(true);
        if (box.isValid()) {
            bbox_ += box;
        }
    }

    if (main_sensors_ && app_ && objContext.parent) {
        app_->putObjectBackIntoDBTree(main_sensors_, objContext);
    }

    if (app_ &&
        !app_->db()->find(static_cast<int>(main_sensors_->getUniqueID()))) {
        if (main_sensors_->getChildrenNumber() > 0) {
            app_->addToDB(main_sensors_);
            // just avoid duplicated rendering
            main_sensors_->setRedrawFlagRecursive(false);
        }
    }
}

void ModelViewerWidget::resetCameraSensors(
        std::vector<ccCameraSensor*>& sensors) {
    clearSensors(sensors);
}

void ModelViewerWidget::clearSensors(std::vector<ccCameraSensor*>& sensors) {
    for (std::size_t i = 0; i < sensors.size(); ++i) {
        if (!sensors[i]) continue;
        if (app_ &&
            app_->db()->find(static_cast<int>(sensors[i]->getUniqueID()))) {
            sensors[i]->setLocked(false);
            if (sensors[i]->isSelected()) {
                // must unselect this sensor to be deleted,
                // otherwise will remain in rendering screen?
                app_->db()->unselectEntity(sensors[i]);
            }
            app_->removeFromDB(sensors[i], true);
        }
        sensors[i] = nullptr;
    }

    if (main_sensors_ && main_sensors_->getChildrenNumber() == 0) {
        if (app_ &&
            app_->db()->find(static_cast<int>(main_sensors_->getUniqueID()))) {
            main_sensors_->setLocked(false);
            app_->removeFromDB(main_sensors_, true);
            main_sensors_ = nullptr;
        }
    }

    sensors.clear();
}

void ModelViewerWidget::updateSensors(
        std::vector<ccCameraSensor*>& sensors,
        const std::vector<colmap::image_t>& image_ids) {
    if (sensors.size() > image_ids.size()) {
        std::vector<ccCameraSensor*> toBeDeleted;
        std::vector<ccCameraSensor*> preserved;
        for (ccCameraSensor* sensor : sensors) {
            if (!sensor) {
                continue;
            }
            colmap::image_t sensorId = sensor->getName().toUInt();
            if (std::find(image_ids.begin(), image_ids.end(), sensorId) ==
                image_ids.end()) {
                toBeDeleted.push_back(sensor);
            } else {
                preserved.push_back(sensor);
            }
        }

        if (!toBeDeleted.empty()) {
            sensors.clear();
            for (ccCameraSensor* sensor : preserved) {
                sensors.push_back(sensor);
            }

            clearSensors(toBeDeleted);
        }
    }
}

ccHObject* ModelViewerWidget::getSelectedCamera(colmap::image_t selected_id) {
    if (main_sensors_ && main_sensors_->getChildrenNumber() > 0) {
        for (unsigned ci = 0; ci != main_sensors_->getChildrenNumber(); ++ci) {
            ccHObject* obj = main_sensors_->getChild(ci);
            if (obj->getName().toUInt() == selected_id) {
                return obj;
            }
        }
    }

    return nullptr;
}

}  // namespace cloudViewer
