// Copyright (c) 2018, ETH Zurich and UNC Chapel Hill.
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//
//     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of
//       its contributors may be used to endorse or promote products derived
//       from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
//
// Author: Johannes L. Schoenberger (jsch-at-demuc-dot-de)

#include "ModelViewerWidget.h"
#include "ReconstructionWidget.h"
#include "RenderOptions.h"
#include "QtUtils.h"

// CV_DB_LIB
#include <ecvCameraSensor.h>
#include <ecvPointCloud.h>
#include <ecvDisplayTools.h>

#define SELECTION_BUFFER_IMAGE_IDX 0
#define SELECTION_BUFFER_POINT_IDX 1

const Eigen::Vector4d kSelectedPointColor(0.0, 1.0, 0.0, 1.0);

const Eigen::Vector4d kSelectedImagePlaneColor(1.0, 0.0, 1.0, 0.6);
const Eigen::Vector4d kSelectedImageFrameColor(0.8, 0.0, 0.8, 1.0);

const Eigen::Vector4d kMovieGrabberImagePlaneColor(0.0, 1.0, 1.0, 0.6);
const Eigen::Vector4d kMovieGrabberImageFrameColor(0.0, 0.8, 0.8, 1.0);

const Eigen::Vector4f kGridColor(0.2f, 0.2f, 0.2f, 0.6f);
const Eigen::Vector4f kXAxisColor(0.9f, 0.0f, 0.0f, 0.5f);
const Eigen::Vector4f kYAxisColor(0.0f, 0.9f, 0.0f, 0.5f);
const Eigen::Vector4f kZAxisColor(0.0f, 0.0f, 0.9f, 0.5f);

namespace cloudViewer {
namespace {

// Generate unique index from RGB color in the range [0, 256^3].
inline size_t RGBToIndex(const uint8_t r, const uint8_t g, const uint8_t b) {
  return static_cast<size_t>(r) + static_cast<size_t>(g) * 256 +
         static_cast<size_t>(b) * 65536;
}

// Derive color from unique index, generated by `RGBToIndex`.
inline Eigen::Vector4f IndexToRGB(const size_t index) {
  Eigen::Vector4f color;
  color(0) = ((index & 0x000000FF) >> 0) / 255.0f;
  color(1) = ((index & 0x0000FF00) >> 8) / 255.0f;
  color(2) = ((index & 0x00FF0000) >> 16) / 255.0f;
  color(3) = 1.0f;
  return color;
}

std::shared_ptr<ccCameraSensor> BuildImageModel( const colmap::Image& image, const colmap::Camera& camera,
                                                 const float image_size, const Eigen::Vector4d& plane_color,
                                                 const Eigen::Vector4d& frame_color) {
  // Generate camera dimensions in OpenGL (world) coordinate space.

  auto sensor = std::make_shared<ccCameraSensor>();
  sensor->setGraphicScale(image_size);

  // set color
  ecvColor::Rgb planeColor = ecvColor::Rgb::FromEigen(
                                          Eigen::Vector3d(plane_color(0),
                                                          plane_color(1),
                                                          plane_color(2)));
  sensor->setPlaneColor(planeColor);
  ecvColor::Rgb frameColor = ecvColor::Rgb::FromEigen(
                                          Eigen::Vector3d(frame_color(0),
                                                          frame_color(1),
                                                          frame_color(2)));
  sensor->setFrameColor(frameColor);

  // temp information
  const float kBaseCameraWidth = 1024.0f;
  const float image_width = image_size * camera.Width() / kBaseCameraWidth;
  const float image_height = image_width * static_cast<float>(camera.Height()) /
                             static_cast<float>(camera.Width());
  const float image_extent = std::max(image_width, image_height);
  const float camera_extent = std::max(camera.Width(), camera.Height());
  const float camera_extent_world =
      static_cast<float>(camera.ImageToWorldThreshold(camera_extent));
  const float focal_length = 2.0f * image_extent / camera_extent_world;

  // init camera intrinsic parameters
  ccCameraSensor::IntrinsicParameters iParams;
  iParams.vertFocal_pix = static_cast<float>(camera.MeanFocalLength());
  iParams.arrayWidth = static_cast<int>(camera.Width());
  iParams.arrayHeight = static_cast<int>(camera.Height());
  iParams.principal_point[0] = static_cast<float>(camera.PrincipalPointX());
  iParams.principal_point[1] = static_cast<float>(camera.PrincipalPointY());
  sensor->setIntrinsicParameters(iParams);

  // init camera rigid transformation parameters
  const Eigen::Matrix<float, 3, 4> proj_matrix = image.ProjectionMatrix().cast<float>();
  Eigen::Matrix3f rotation = proj_matrix.leftCols<3>();
  Eigen::Vector3f translation = proj_matrix.rightCols<1>();
  ccGLMatrix rot = ccGLMatrix::FromEigenMatrix(rotation);
  rot.setTranslation(translation.data());
  sensor->setRigidTransformation(rot);

  return sensor;
}

}  // namespace

using namespace colmap;
ModelViewerWidget::ModelViewerWidget(QWidget* parent, OptionManager* options)
    : QWidget(parent),
      statusbar_status_label(nullptr),
      options_(options),
      point_viewer_widget_(new PointViewerWidget(parent, this, options)),
      image_viewer_widget_(
          new DatabaseImageViewerWidget(parent, this, options)),
      movie_grabber_widget_(new MovieGrabberWidget(parent, this)),
      mouse_is_pressed_(false),
      focus_distance_(kInitFocusDistance),
      selected_image_id_(kInvalidImageId),
      selected_point3D_id_(kInvalidPoint3DId),
      coordinate_grid_enabled_(true),
      near_plane_(kInitNearPlane) {

  SetupView();
  SetPointColormap(new PointColormapPhotometric());
  SetImageColormap(new ImageColormapUniform());

  image_size_ = static_cast<float>(ecvDisplayTools::GetDevicePixelRatio() * image_size_);
  point_size_ = static_cast<float>(ecvDisplayTools::GetDevicePixelRatio() * point_size_);

  point_line_data_.clear();
  image_line_data_.clear();
  sensors_.clear();

  cloud_sparse_ = new ccPointCloud("sparseCloud");
  if (cloud_dense_->reserveThePointsTable(1))
  {
      cloud_sparse_->reserveTheRGBTable();
      cloud_sparse_->showColors(true);
      cloud_sparse_->setPointSize(static_cast<unsigned>(point_size_));
  }
  else
  {
    CVLog::Warning("[ModelViewerWidget] Not enough memory!");
  }

  cloud_dense_ = new ccPointCloud("denseCloud");
  if (cloud_dense_->reserveThePointsTable(1))
  {
      cloud_dense_->reserveTheRGBTable();
      cloud_dense_->showColors(true);
      cloud_dense_->setPointSize(static_cast<unsigned>(point_size_));
  }
  else
  {
    CVLog::Warning("[ModelViewerWidget] Not enough memory!");
  }

}

ModelViewerWidget::~ModelViewerWidget()
{
    if (cloud_sparse_)
        delete cloud_sparse_;
    if (cloud_dense_)
        delete cloud_dense_;
}

void ModelViewerWidget::ReloadReconstruction() {
  if (reconstruction == nullptr) {
    return;
  }

  cameras = reconstruction->Cameras();
  points3D = reconstruction->Points3D();
  reg_image_ids = reconstruction->RegImageIds();

  images.clear();
  for (const image_t image_id : reg_image_ids) {
    images[image_id] = reconstruction->Image(image_id);
  }

  if (statusbar_status_label)
  {
      statusbar_status_label->setText(QString().sprintf(
          "%d Images - %d Points", static_cast<int>(reg_image_ids.size()),
          static_cast<int>(points3D.size())));
  }

  Upload();
}

void ModelViewerWidget::ClearReconstruction() {
  cameras.clear();
  images.clear();
  points3D.clear();
  reg_image_ids.clear();
  reconstruction = nullptr;
  Upload();
}

int ModelViewerWidget::GetProjectionType() const {
  return options_->render->projection_type;
}

void ModelViewerWidget::SetPointColormap(PointColormapBase* colormap) {
  point_colormap_.reset(colormap);
}

void ModelViewerWidget::SetImageColormap(ImageColormapBase* colormap) {
  image_colormap_.reset(colormap);
}

void ModelViewerWidget::UpdateMovieGrabber() {
  UploadMovieGrabberData();
  update();
}

void ModelViewerWidget::ChangeFocusDistance(const float delta) {
  if (delta == 0.0f) {
    return;
  }
  const float prev_focus_distance = focus_distance_;
  float diff = delta * ZoomScale() * kFocusSpeed;
  focus_distance_ -= diff;
  if (focus_distance_ < kMinFocusDistance) {
    focus_distance_ = kMinFocusDistance;
    diff = prev_focus_distance - focus_distance_;
  } else if (focus_distance_ > kMaxFocusDistance) {
    focus_distance_ = kMaxFocusDistance;
    diff = prev_focus_distance - focus_distance_;
  }
  const Eigen::Matrix4f vm_mat = QMatrixToEigen(model_view_matrix_).inverse();
  const Eigen::Vector3f tvec(0, 0, diff);
  const Eigen::Vector3f tvec_rot = vm_mat.block<3, 3>(0, 0) * tvec;
  model_view_matrix_.translate(tvec_rot(0), tvec_rot(1), tvec_rot(2));
  ComposeProjectionMatrix();
  update();
}

void ModelViewerWidget::ChangeNearPlane(const float delta) {
  if (delta == 0.0f) {
    return;
  }
  near_plane_ *= (1.0f + delta / 100.0f * kNearPlaneScaleSpeed);
  near_plane_ = std::max(kMinNearPlane, std::min(kMaxNearPlane, near_plane_));
  ComposeProjectionMatrix();
  update();
}

void ModelViewerWidget::ChangePointSize(const float delta) {
  if (delta == 0.0f) {
    return;
  }
  point_size_ *= (1.0f + delta / 100.0f * kPointScaleSpeed);
  point_size_ = std::max(kMinPointSize, std::min(kMaxPointSize, point_size_));
  update();
}

void ModelViewerWidget::ChangeCameraSize(const float delta) {
  if (delta == 0.0f) {
    return;
  }
  image_size_ *= (1.0f + delta / 100.0f * kImageScaleSpeed);
  image_size_ = std::max(kMinImageSize, std::min(kMaxImageSize, image_size_));
  UploadImageData();
  UploadMovieGrabberData();
  update();
}

QMatrix4x4 ModelViewerWidget::ModelViewMatrix() const {
  return model_view_matrix_;
}

void ModelViewerWidget::SetModelViewMatrix(const QMatrix4x4& matrix) {
  model_view_matrix_ = matrix;
  update();
}

void ModelViewerWidget::SelectObject(const int x, const int y) {
  // Upload data in selection mode (one color per object).
  UploadImageData(true);
  UploadPointData(true);

  // Render in selection mode, with larger points to improve selection accuracy.
  const QMatrix4x4 pmv_matrix = projection_matrix_ * model_view_matrix_;
//  image_triangle_painter_.Render(pmv_matrix);
//  point_painter_.Render(pmv_matrix, 2 * point_size_);

  CCVector2i scaled_coords(x, y);
  ecvDisplayTools::ToVtkCoordinates(scaled_coords);
  QString obj_id = ecvDisplayTools::Pick3DItem(scaled_coords.x, scaled_coords.y);
  std::array<uint8_t, 3> color;

  const size_t index = RGBToIndex(color[0], color[1], color[2]);

  if (index < selection_buffer_.size()) {
    const char buffer_type = selection_buffer_[index].second;
    if (buffer_type == SELECTION_BUFFER_IMAGE_IDX) {
      selected_image_id_ = static_cast<image_t>(selection_buffer_[index].first);
      selected_point3D_id_ = kInvalidPoint3DId;
      ShowImageInfo(selected_image_id_);
    } else if (buffer_type == SELECTION_BUFFER_POINT_IDX) {
      selected_image_id_ = kInvalidImageId;
      selected_point3D_id_ = selection_buffer_[index].first;
      ShowPointInfo(selection_buffer_[index].first);
    } else {
      selected_image_id_ = kInvalidImageId;
      selected_point3D_id_ = kInvalidPoint3DId;
      image_viewer_widget_->hide();
    }
  } else {
    selected_image_id_ = kInvalidImageId;
    selected_point3D_id_ = kInvalidPoint3DId;
    image_viewer_widget_->hide();
  }

  selection_buffer_.clear();

  UploadPointData();
  UploadImageData();
  UploadPointConnectionData();
  UploadImageConnectionData();

  update();
}

void ModelViewerWidget::SelectMoviewGrabberView(const size_t view_idx) {
  selected_movie_grabber_view_ = view_idx;
  UploadMovieGrabberData();
  update();
}

QImage ModelViewerWidget::GrabImage() {
    // render to image
    return ecvDisplayTools::RenderToImage(1, false, true, 0);
}

void ModelViewerWidget::GrabMovie() { movie_grabber_widget_->show(); }

void ModelViewerWidget::ShowPointInfo(const point3D_t point3D_id) {
  point_viewer_widget_->Show(point3D_id);
}

void ModelViewerWidget::ShowImageInfo(const image_t image_id) {
  image_viewer_widget_->ShowImageWithId(image_id);
}

float ModelViewerWidget::PointSize() const { return point_size_; }

float ModelViewerWidget::ImageSize() const { return image_size_; }

void ModelViewerWidget::SetPointSize(const float point_size) {
  point_size_ = point_size;
}

void ModelViewerWidget::SetImageSize(const float image_size) {
  image_size_ = image_size;
  UploadImageData();
}

void ModelViewerWidget::mousePressEvent(QMouseEvent* event) {
  if (mouse_press_timer_.isActive()) {  // Select objects (2. click)
    mouse_is_pressed_ = false;
    mouse_press_timer_.stop();
    selection_buffer_.clear();
    SelectObject(event->pos().x(), event->pos().y());
  } else {  // Set timer to remember 1. click
    mouse_press_timer_.setSingleShot(true);
    mouse_press_timer_.start(kDoubleClickInterval);
    mouse_is_pressed_ = true;
    prev_mouse_pos_ = event->pos();
  }
  event->accept();
}

void ModelViewerWidget::wheelEvent(QWheelEvent* event) {
  if (event->modifiers() & Qt::ControlModifier) {
    ChangePointSize(event->delta());
  } else if (event->modifiers() & Qt::AltModifier) {
    ChangeCameraSize(event->delta());
  } else if (event->modifiers() & Qt::ShiftModifier) {
    ChangeNearPlane(event->delta());
  } else {
    ChangeFocusDistance(event->delta());
  }
  event->accept();
}

void ModelViewerWidget::SetupView() {
  point_size_ = kInitPointSize;
  image_size_ = kInitImageSize;
  focus_distance_ = kInitFocusDistance;
  model_view_matrix_.setToIdentity();
  model_view_matrix_.translate(0, 0, -focus_distance_);
  model_view_matrix_.rotate(225, 1, 0, 0);
  model_view_matrix_.rotate(-45, 0, 1, 0);
}

void ModelViewerWidget::Upload() {
  point_colormap_->Prepare(cameras, images, points3D, reg_image_ids);
  image_colormap_->Prepare(cameras, images, points3D, reg_image_ids);

  ComposeProjectionMatrix();

  UploadPointData();
  UploadImageData();
  UploadMovieGrabberData();
  UploadPointConnectionData();
  UploadImageConnectionData();

  update();
}

void ModelViewerWidget::UploadPointData(const bool selection_mode) {
  if (!cloud_sparse_)
  {
      CVLog::Warning("[ModelViewerWidget::UploadPointData] Not enough memory!");
      return;
  }

  cloud_sparse_->clear();

  if (points3D.size() == 0)
  {
      resetPointCloud(cloud_sparse_);
      return;
  }

  // Assume we want to display the majority of points
  if (!cloud_sparse_->reserve(static_cast<unsigned>(points3D.size())))
  {
      cloud_sparse_->reserve(static_cast<unsigned>(points3D.size()));
      return;
  } else {
      cloud_sparse_->reserveTheRGBTable();
  }

  const size_t min_track_len =
      static_cast<size_t>(options_->render->min_track_len);

  if (selected_image_id_ == kInvalidImageId &&
      images.count(selected_image_id_) == 0) {
    for (const auto& point3D : points3D) {
      if (point3D.second.Error() <= options_->render->max_error &&
          point3D.second.Track().Length() >= min_track_len) {
        CCVector3 painter_point;
        painter_point.x = static_cast<PointCoordinateType>(point3D.second.XYZ(0));
        painter_point.y = static_cast<PointCoordinateType>(point3D.second.XYZ(1));
        painter_point.z = static_cast<PointCoordinateType>(point3D.second.XYZ(2));
        cloud_sparse_->addPoint(painter_point);

        Eigen::Vector4d color;
        if (selection_mode) {
          const size_t index = selection_buffer_.size();
          selection_buffer_.push_back(
              std::make_pair(point3D.first, SELECTION_BUFFER_POINT_IDX));
          color = IndexToRGB(index).cast<double>();

        } else if (point3D.first == selected_point3D_id_) {
          color = kSelectedPointColor;
        } else {
          color = point_colormap_->ComputeColor(point3D.first, point3D.second).cast<double>();
        }

        ecvColor::Rgb pointColor = ecvColor::Rgb::FromEigen(Eigen::Vector3d(color(0), color(1), color(2)));
        cloud_sparse_->addRGBColor(pointColor);
      }
    }
  } else {  // Image selected
    const auto& selected_image = images[selected_image_id_];
    for (const auto& point3D : points3D) {
      if (point3D.second.Error() <= options_->render->max_error &&
          point3D.second.Track().Length() >= min_track_len) {
        CCVector3 painter_point;
        painter_point.x = static_cast<PointCoordinateType>(point3D.second.XYZ(0));
        painter_point.y = static_cast<PointCoordinateType>(point3D.second.XYZ(1));
        painter_point.z = static_cast<PointCoordinateType>(point3D.second.XYZ(2));
        cloud_sparse_->addPoint(painter_point);

        Eigen::Vector4d color;
        if (selection_mode) {
          const size_t index = selection_buffer_.size();
          selection_buffer_.push_back(
              std::make_pair(point3D.first, SELECTION_BUFFER_POINT_IDX));
          color = IndexToRGB(index).cast<double>();
        } else if (selected_image.HasPoint3D(point3D.first)) {
          color = kSelectedImagePlaneColor;
        } else if (point3D.first == selected_point3D_id_) {
          color = kSelectedPointColor;
        } else {
          color = point_colormap_->ComputeColor(point3D.first, point3D.second).cast<double>();
        }

        ecvColor::Rgb pointColor = ecvColor::Rgb::FromEigen(Eigen::Vector3d(color(0), color(1), color(2)));
        cloud_sparse_->addRGBColor(pointColor);
      }
    }
  }

  drawPointCloud(cloud_sparse_);
}

void ModelViewerWidget::UploadPointConnectionData() {
  if (selected_point3D_id_ == kInvalidPoint3DId) {
    // No point selected, so upload empty data
    return;
  }

  point_line_data_.clear();
  const auto& point3D = points3D[selected_point3D_id_];
  if (point3D.Track().Elements().size() == 0)
  {
      resetLines(point_line_data_);
      return;
  }

  // 3D point position.
  point_line_data_.points_.push_back(point3D.XYZ());

  // All images in which 3D point is observed.
  int index = 0;
  for (const auto& track_el : point3D.Track().Elements()) {
    const Image& conn_image = images[track_el.image_id];
    const Eigen::Vector3d conn_proj_center = conn_image.ProjectionCenter();
    point_line_data_.points_.push_back(conn_proj_center);
    point_line_data_.lines_.push_back(Eigen::Vector2i(0, ++index));
  }

  point_line_data_.paintUniformColor(Eigen::Vector3d(kSelectedPointColor(0),
                                                    kSelectedPointColor(1),
                                                    kSelectedPointColor(2)));
  drawLines(point_line_data_);
}

void ModelViewerWidget::UploadImageData(const bool selection_mode) {

  std::size_t lastSensorNum = sensors_.size();
  std::size_t curSensorNum = reg_image_ids.size();

  if (curSensorNum == 0)
  {
      resetCameraSensors(sensors_);
      return;
  }

  if (lastSensorNum < curSensorNum)
  {
      sensors_.reserve(curSensorNum);
  }

  std::size_t index = 0;
  for (const image_t image_id : reg_image_ids) {
    const Image& image = images[image_id];
    const Camera& camera = cameras[image.CameraId()];

    Eigen::Vector4f plane_color;
    Eigen::Vector4f frame_color;
    if (selection_mode) {
      const size_t index = selection_buffer_.size();
      selection_buffer_.push_back(
          std::make_pair(image_id, SELECTION_BUFFER_IMAGE_IDX));
      plane_color = frame_color = IndexToRGB(index);
    } else {
      if (image_id == selected_image_id_) {
        plane_color = kSelectedImagePlaneColor.cast<float>();
        frame_color = kSelectedImageFrameColor.cast<float>();
      } else {
        image_colormap_->ComputeColor(image, &plane_color, &frame_color);
      }
    }

    // Lines are not colored with the indexed color in selection mode, so do not
    // show them, so they do not block the selection process
    auto sensor = BuildImageModel(image, camera, image_size_,
                                  plane_color.cast<double>(),
                                  frame_color.cast<double>());

    if (index < lastSensorNum)
    {
        sensors_[index].reset(sensor.get());
    }
    else
    {
        sensors_.push_back(sensor);
    }
    index++;
  }

  drawCameraSensors(sensors_);
}

void ModelViewerWidget::UploadImageConnectionData() {
  std::vector<image_t> image_ids;

  if (selected_image_id_ != kInvalidImageId) {
    // Show connections to selected images
    image_ids.push_back(selected_image_id_);
  } else if (options_->render->image_connections) {
    // Show all connections
    image_ids = reg_image_ids;
  } else {  // Disabled, so upload empty data
//    image_connection_painter_.Upload(line_data);
    return;
  }

  image_line_data_.clear();

  if (image_ids.size() == 0)
  {
      resetLines(image_line_data_);
      return;
  }

  for (const image_t image_id : image_ids) {
    const Image& image = images.at(image_id);

    const Eigen::Vector3d proj_center = image.ProjectionCenter();

    // Collect all connected images
    std::unordered_set<image_t> conn_image_ids;

    for (const Point2D& point2D : image.Points2D()) {
      if (point2D.HasPoint3D()) {
        const Point3D& point3D = points3D[point2D.Point3DId()];
        for (const auto& track_elem : point3D.Track().Elements()) {
          conn_image_ids.insert(track_elem.image_id);
        }
      }
    }

    // Selected image in the center.
    int centerIndex = static_cast<int>(image_line_data_.points_.size());
    image_line_data_.points_.push_back(proj_center);

    // All connected images to the selected image.
    int index = centerIndex;
    for (const image_t conn_image_id : conn_image_ids) {
      const Image& conn_image = images[conn_image_id];
      const Eigen::Vector3d conn_proj_center = conn_image.ProjectionCenter();
      image_line_data_.points_.push_back(conn_proj_center);
      image_line_data_.lines_.push_back(Eigen::Vector2i(centerIndex, ++index));
    }
  }

  image_line_data_.paintUniformColor(Eigen::Vector3d(kSelectedImageFrameColor(0),
                                                    kSelectedImageFrameColor(1),
                                                    kSelectedImageFrameColor(2)));
  drawLines(image_line_data_);
}

void ModelViewerWidget::UploadMovieGrabberData() {
  std::size_t lastSensorNum = movie_grabber_sensors_.size();
  std::size_t curSensorNum = movie_grabber_widget_->views.size();

  if (lastSensorNum < curSensorNum)
  {
      movie_grabber_sensors_.reserve(curSensorNum);
  }

  movie_grabber_path_.clear();

  if (movie_grabber_widget_->views.size() > 0) {
    const Image& image0 = movie_grabber_widget_->views[0];
    Eigen::Vector3d prev_proj_center = image0.ProjectionCenter();

    for (size_t i = 1; i < movie_grabber_widget_->views.size(); ++i) {
      const Image& image = movie_grabber_widget_->views[i];
      const Eigen::Vector3d curr_proj_center = image.ProjectionCenter();
      movie_grabber_path_.points_.push_back(prev_proj_center);
      movie_grabber_path_.points_.push_back(curr_proj_center);
      std::size_t start = movie_grabber_path_.points_.size() - 2;
      std::size_t end = movie_grabber_path_.points_.size() - 1;
      movie_grabber_path_.lines_.push_back(Eigen::Vector2i(start, end));
      prev_proj_center = curr_proj_center;
    }
    movie_grabber_path_.paintUniformColor(Eigen::Vector3d(kSelectedImageFrameColor(0),
                                                          kSelectedImageFrameColor(1),
                                                          kSelectedImageFrameColor(2)));

    // Setup dummy camera with same settings as current OpenGL viewpoint.
    const unsigned long kDefaultImageWdith = 2048;
    const unsigned long kDefaultImageHeight = 1536;
    const double focal_length =
        -2.0 * std::tan(DegToRad(ecvDisplayTools::GetCameraFovy()) / 2.0) * kDefaultImageWdith;
    Camera camera;
    camera.InitializeWithId(SimplePinholeCameraModel::model_id, focal_length,
                            kDefaultImageWdith, kDefaultImageHeight);

    // Build all camera models
    std::size_t index = 0;
    for (size_t i = 0; i < movie_grabber_widget_->views.size(); ++i) {
      const Image& image = movie_grabber_widget_->views[i];
      Eigen::Vector4d plane_color;
      Eigen::Vector4d frame_color;
      if (i == selected_movie_grabber_view_) {
        plane_color = kSelectedImagePlaneColor;
        frame_color = kSelectedImageFrameColor;
      } else {
        plane_color = kMovieGrabberImagePlaneColor;
        frame_color = kMovieGrabberImageFrameColor;
      }

      auto sensor = BuildImageModel(image, camera, image_size_,
                                    plane_color, frame_color);
      if (index < lastSensorNum)
      {
          movie_grabber_sensors_[index].reset(sensor.get());
      }
      else
      {
          movie_grabber_sensors_.push_back(sensor);
      }
      index++;
    }

    drawLines(movie_grabber_path_);
    drawCameraSensors(movie_grabber_sensors_);
  } else {
      resetLines(movie_grabber_path_);
      resetCameraSensors(movie_grabber_sensors_);
      return;
  }

}

void ModelViewerWidget::update()
{
    ecvDisplayTools::UpdateScreen();
}

void ModelViewerWidget::drawPointCloud(ccPointCloud *cloud)
{
    if (!cloud)
    {
        return;
    }

    CC_DRAW_CONTEXT context;

    //we get display parameters
    glDrawParams glParams;
    cloud->getDrawingParameters(glParams);

    if (glParams.showColors && cloud->isColorOverriden())
    {
        //ccGL::Color3v(glFunc, m_tempColor.rgb);
        context.pointsCurrentCol = cloud->getTempColor();
        glParams.showColors = false;
    }
    else
    {
        context.pointsCurrentCol = context.pointsDefaultCol;
    }

    // start draw point cloud
    context.drawParam = glParams;
    //custom point size?
    if (cloud->getPointSize() > 0 && cloud->getPointSize() <= MAX_POINT_SIZE_F)
    {
        context.defaultPointSize = cloud->getPointSize();
    }

    ecvDisplayTools::Draw(context, cloud);
}

void ModelViewerWidget::resetPointCloud(ccPointCloud *cloud)
{
    CC_DRAW_CONTEXT context;
    context.removeViewID = QString::number(cloud->getUniqueID(), 10);
    context.removeEntityType = cloud->getEntityType();
    ecvDisplayTools::RemoveEntities(context);
}

void ModelViewerWidget::drawLines(geometry::LineSet &lineset)
{
    CC_DRAW_CONTEXT context;
    if (lineset.isColorOverriden())
    {
        context.defaultPolylineColor = lineset.getTempColor();
    }
    else if (lineset.colorsShown() && lineset.hasColors())
    {
        context.defaultPolylineColor = ecvColor::Rgb::FromEigen(lineset.colors_[0]);
    }

    context.currentLineWidth = 1;
    ecvDisplayTools::Draw(context, &lineset);
}

void ModelViewerWidget::resetLines(geometry::LineSet &lineset)
{
    CC_DRAW_CONTEXT context;
    context.removeViewID = QString::number(lineset.getUniqueID(), 10);
    context.removeEntityType = lineset.getEntityType();
    ecvDisplayTools::RemoveEntities(context);
}

void ModelViewerWidget::drawCameraSensors(std::vector<std::shared_ptr<ccCameraSensor>>& sensors)
{
    CC_DRAW_CONTEXT context;
    for (std::size_t i = 0; i < sensors.size(); ++i) {
        if (!sensors[i])
            continue;

        context.currentLineWidth = 1;
        context.defaultPolylineColor = sensors[i]->getFrameColor();
        context.defaultMeshColor = sensors[i]->getPlaneColor();
        context.opacity = 0.2f;
        {
            ccIndexedTransformation sensorPos;
            if (!sensors[i]->getAbsoluteTransformation(sensorPos,
                                                       sensors[i]->getActiveIndex()))
            {
                //no visible position for this index!
                continue;
            }
            context.transformInfo.setTransformation(sensorPos, true, true);
        }

        // update drawing data
        sensors[i]->updateData();

        context.visible = context.visible;
        context.viewID = context.viewID;
        ecvDisplayTools::Draw(context, sensors[i].get());
    }
}

void ModelViewerWidget::resetCameraSensors(std::vector<std::shared_ptr<ccCameraSensor> > &sensors)
{
    CC_DRAW_CONTEXT context;
    for (std::size_t i = 0; i < sensors.size(); ++i) {
        if (!sensors[i])
            continue;
        sensors[i]->clearDrawings(context);
    }
}

void ModelViewerWidget::ComposeProjectionMatrix() {
  projection_matrix_.setToIdentity();
  if (options_->render->projection_type ==
      RenderOptions::ProjectionType::PERSPECTIVE) {
    projection_matrix_.perspective(kFieldOfView, AspectRatio(), near_plane_,
                                   kFarPlane);
  } else if (options_->render->projection_type ==
             RenderOptions::ProjectionType::ORTHOGRAPHIC) {
    const float extent = OrthographicWindowExtent();
    projection_matrix_.ortho(-AspectRatio() * extent, AspectRatio() * extent,
                             -extent, extent, near_plane_, kFarPlane);
  }
}

float ModelViewerWidget::ZoomScale() const {
  // "Constant" scale factor w.r.t. zoom-level.
//  const ecvViewportParameters& viewParams = ecvDisplayTools::GetViewportParameters();
  return 2.0f * std::tan(static_cast<float>(DegToRad(ecvDisplayTools::GetCameraFovy())) / 2.0f) *
         std::abs(focus_distance_) / ecvDisplayTools::GlHeight();
}

float ModelViewerWidget::AspectRatio() const {
  return static_cast<float>(ecvDisplayTools::GlWidth()) /
          static_cast<float>(ecvDisplayTools::GlHeight());
}

float ModelViewerWidget::OrthographicWindowExtent() const {
  return std::tan(DegToRad(ecvDisplayTools::GetCameraFovy()) / 2.0f) * focus_distance_;
}

Eigen::Vector3f ModelViewerWidget::PositionToArcballVector(
    const float x, const float y) const {
  Eigen::Vector3f vec(2.0f * x / ecvDisplayTools::GlWidth() - 1,
                      1 - 2.0f * y / ecvDisplayTools::GlHeight(), 0.0f);
  const float norm2 = vec.squaredNorm();
  if (norm2 <= 1.0f) {
    vec.z() = std::sqrt(1.0f - norm2);
  } else {
    vec = vec.normalized();
  }
  return vec;
}

}  // namespace cloudViewer
