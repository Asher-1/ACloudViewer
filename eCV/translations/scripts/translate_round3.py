#!/usr/bin/env python3
"""
Round 3 Translation - Handle remaining 266 entries
Focus on error messages with parameters, console outputs, and technical descriptions
"""

import xml.etree.ElementTree as ET
import re

# Round 3: Complex error messages, console outputs, technical formulas
ROUND3_TRANSLATIONS = {
    # Complex error messages with parameters
    "Hum, it seems that ECV has crashed... Sorry about that :) ": "å—¯ï¼Œçœ‹èµ·æ¥ECVå´©æºƒäº†...å¯¹æ­¤æ„Ÿåˆ°æŠ±æ­‰ :) ",
    "Missing parameter: number of lines after '%1'": "ç¼ºå°‘å‚æ•°ï¼š'%1' åçš„è¡Œæ•°",
    "Missing parameter: global shift vector or %1 after '%2'": "ç¼ºå°‘å‚æ•°ï¼š'%2' åçš„å…¨å±€åç§»å‘é‡æˆ– %1",
    "Missing parameter: global shift vector after '%1' (3 values expected)": "ç¼ºå°‘å‚æ•°ï¼š'%1' åçš„å…¨å±€åç§»å‘é‡ï¼ˆéœ€è¦3ä¸ªå€¼ï¼‰",
    "Missing parameter: radius after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„åŠå¾„",
    "Missing parameter: resampling method after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„é‡é‡‡æ ·æ–¹æ³•",
    "Missing parameter: number of points after \"-%1 RANDOM\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1 RANDOM\" åçš„ç‚¹æ•°",
    "\tResult: %1 points": "\tç»“æœï¼š%1 ä¸ªç‚¹",
    "Missing parameter: spatial step after \"-%1 SPATIAL\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1 SPATIAL\" åçš„ç©ºé—´æ­¥é•¿",
    "\tSpatial step: %1": "\tç©ºé—´æ­¥é•¿ï¼š%1",
    "Missing parameter: octree level after \"-%1 OCTREE\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1 OCTREE\" åçš„å…«å‰æ ‘å±‚çº§",
    "\tOctree level: %1": "\tå…«å‰æ ‘å±‚çº§ï¼š%1",
    "OCTREE_LEVEL_%1_SUBSAMPLED": "å…«å‰æ ‘å±‚çº§_%1_é™é‡‡æ ·",
    "Missing parameter: octree level after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„å…«å‰æ ‘å±‚çº§",
    "Missing parameter: minimum number of points per component after \"-%1 [octree level]\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1 [å…«å‰æ ‘å±‚çº§]\" åæ¯ä¸ªç»„ä»¶çš„æœ€å°ç‚¹æ•°",
    "%1 component(s) were created": "åˆ›å»ºäº† %1 ä¸ªç»„ä»¶",
    "Missing parameter: curvature type after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„æ›²ç‡ç±»å‹",
    "\tKernel size: %1": "\tæ ¸å¤§å°ï¼š%1",
    "%1_CURVATURE_KERNEL_%2": "%1_æ›²ç‡_æ ¸_%2",
    "Missing parameter: density type after \"-%1\" (KNN/SURFACE/VOLUME)": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„å¯†åº¦ç±»å‹ï¼ˆKNN/SURFACE/VOLUMEï¼‰",
    "Missing parameter: sphere radius after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„çƒåŠå¾„",
    "Missing parameter: boolean (whether SF is euclidean or not) after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„å¸ƒå°”å€¼ï¼ˆæ ‡é‡åœºæ˜¯å¦ä¸ºæ¬§æ°ï¼‰",
    "cmd.warning: cloud '%1' has no scalar field (it will be ignored)": "å‘½ä»¤è­¦å‘Šï¼šç‚¹äº‘ '%1' æ²¡æœ‰æ ‡é‡åœºï¼ˆå°†è¢«å¿½ç•¥ï¼‰",
    "cmd.warning: cloud '%1' has several scalar fields (the active one will be used by default, or the first one if none is active)": "å‘½ä»¤è­¦å‘Šï¼šç‚¹äº‘ '%1' æœ‰å¤šä¸ªæ ‡é‡åœºï¼ˆé»˜è®¤ä½¿ç”¨æ´»åŠ¨çš„ï¼Œå¦‚æœæ²¡æœ‰æ´»åŠ¨çš„åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼‰",
    "Missing parameter: kernel size after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„æ ¸å¤§å°",
    "Missing parameter: transformation file after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„å˜æ¢æ–‡ä»¶",
    "Missing parameter: color scale file after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„è‰²é˜¶æ–‡ä»¶",
    "Missing parameter: boolean (whether to mix with existing colors or not) after \"-%1\"": "ç¼ºå°‘å‚æ•°ï¼š\"-%1\" åçš„å¸ƒå°”å€¼ï¼ˆæ˜¯å¦ä¸ç°æœ‰é¢œè‰²æ··åˆï¼‰",
    "cmd.warning: cloud '%1' has no active scalar field (it will be ignored)": "å‘½ä»¤è­¦å‘Šï¼šç‚¹äº‘ '%1' æ²¡æœ‰æ´»åŠ¨æ ‡é‡åœºï¼ˆå°†è¢«å¿½ç•¥ï¼‰",
    "cmd.warning: cloud '%1' failed to convert SF to RGB": "å‘½ä»¤è­¦å‘Šï¼šç‚¹äº‘ '%1' æ— æ³•å°†æ ‡é‡åœºè½¬æ¢ä¸ºRGB",
    
    # MainWindow error messages
    "Entity '%1' has been translated: (%2,%3,%4) and rescaled of a factor %5 [original position will be restored after saving]": 
        "å®ä½“ '%1' å·²è¢«å¹³ç§»ï¼š(%2,%3,%4) å¹¶æŒ‰å› å­ %5 é‡æ–°ç¼©æ”¾ [ä¿å­˜åå°†æ¢å¤åŸå§‹ä½ç½®]",
    "[Subdivide] An error occurred while trying to subdivide mesh '%1' (not enough memory?)": "[ç»†åˆ†] å°è¯•ç»†åˆ†ç½‘æ ¼ '%1' æ—¶å‘ç”Ÿé”™è¯¯ï¼ˆå†…å­˜ä¸è¶³ï¼Ÿï¼‰",
    "[Subdivide] Works only on real meshes!": "[ç»†åˆ†] ä»…é€‚ç”¨äºçœŸå®ç½‘æ ¼ï¼",
    "[changeLanguage] Change to English language": "[åˆ‡æ¢è¯­è¨€] åˆ‡æ¢åˆ°è‹±è¯­",
    "[changeLanguage] Doesn't support Chinese temporarily": "[åˆ‡æ¢è¯­è¨€] æš‚ä¸æ”¯æŒä¸­æ–‡",
    "An error occurred while cloning cloud %1": "å…‹éš†ç‚¹äº‘ %1 æ—¶å‘ç”Ÿé”™è¯¯",
    "An error occurred while cloning primitive %1": "å…‹éš†åŸºå…ƒ %1 æ—¶å‘ç”Ÿé”™è¯¯",
    "An error occurred while cloning mesh %1": "å…‹éš†ç½‘æ ¼ %1 æ—¶å‘ç”Ÿé”™è¯¯",
    "An error occurred while cloning polyline %1": "å…‹éš†æŠ˜çº¿ %1 æ—¶å‘ç”Ÿé”™è¯¯",
    "An error occurred while cloning facet %1": "å…‹éš†é¢ç‰‡ %1 æ—¶å‘ç”Ÿé”™è¯¯",
    "Entity '%1' can't be cloned (type not supported yet!)": "å®ä½“ '%1' æ— æ³•å…‹éš†ï¼ˆç±»å‹æš‚ä¸æ”¯æŒï¼ï¼‰",
    "This method is for test purpose only": "æ­¤æ–¹æ³•ä»…ç”¨äºæµ‹è¯•",
    "Couldn't allocate a new scalar field for computing distances! Try to free some memory ...": "æ— æ³•åˆ†é…æ–°çš„æ ‡é‡åœºæ¥è®¡ç®—è·ç¦»ï¼å°è¯•é‡Šæ”¾ä¸€äº›å†…å­˜...",
    "This method is still under development: are you sure you want to use it? (a crash may likely happen)": "æ­¤æ–¹æ³•ä»åœ¨å¼€å‘ä¸­ï¼šç¡®å®šè¦ä½¿ç”¨å®ƒå—ï¼Ÿï¼ˆå¯èƒ½ä¼šå´©æºƒï¼‰",
    "[Align] Resulting matrix:": "[å¯¹é½] ç»“æœçŸ©é˜µï¼š",
    "[Register] ": "[é…å‡†] ",
    "[Register] Applied transformation matrix:": "[é…å‡†] åº”ç”¨çš„å˜æ¢çŸ©é˜µï¼š",
    "Theoretical overlap: %1%": "ç†è®ºé‡å ï¼š%1%",
    "This report has been output to Console (F8)": "æ­¤æŠ¥å‘Šå·²è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆF8ï¼‰",
    "Data mesh vertices are locked (they may be shared with other meshes): Do you wish to clone this mesh to apply transformation?": "æ•°æ®ç½‘æ ¼é¡¶ç‚¹å·²é”å®šï¼ˆå®ƒä»¬å¯èƒ½ä¸å…¶ä»–ç½‘æ ¼å…±äº«ï¼‰ï¼šæ˜¯å¦è¦å…‹éš†æ­¤ç½‘æ ¼ä»¥åº”ç”¨å˜æ¢ï¼Ÿ",
    "Doesn't work on sub-meshes yet!": "å°šä¸æ”¯æŒå­ç½‘æ ¼ï¼",
    "Drop shift information?": "æ”¾å¼ƒåç§»ä¿¡æ¯ï¼Ÿ",
    "Spherical extraction test (%1)": "çƒå½¢æå–æµ‹è¯• (%1)",
    "Couldn't compute octree for cloud '%1'!": "æ— æ³•ä¸ºç‚¹äº‘ '%1' è®¡ç®—å…«å‰æ ‘ï¼",
    "[SNE_TEST] Mean extraction time = %1 ms (radius = %2, mean(neighbours) = %3)": "[SNE_TEST] å¹³å‡æå–æ—¶é—´ = %1 æ¯«ç§’ï¼ˆåŠå¾„ = %2ï¼Œå¹³å‡é‚»åŸŸ = %3ï¼‰",
    "[CNE_TEST] Mean extraction time = %1 ms (radius = %2, height = %3, mean(neighbours) = %4)": "[CNE_TEST] å¹³å‡æå–æ—¶é—´ = %1 æ¯«ç§’ï¼ˆåŠå¾„ = %2ï¼Œé«˜åº¦ = %3ï¼Œå¹³å‡é‚»åŸŸ = %4ï¼‰",
    "Need at least two clouds!": "è‡³å°‘éœ€è¦ä¸¤ä¸ªç‚¹äº‘ï¼",
    "%1 clouds and %2 positions": "%1 ä¸ªç‚¹äº‘å’Œ %2 ä¸ªä½ç½®",
    "Orthogonal dim (X=0 / Y=1 / Z=2)": "æ­£äº¤ç»´åº¦ï¼ˆX=0 / Y=1 / Z=2ï¼‰",
    "%1 (%2 values) ": "%1ï¼ˆ%2 ä¸ªå€¼ï¼‰",
    
    # qFacets errors
    "closing facets dialog failed! [%1]": "å…³é—­é¢ç‰‡å¯¹è¯æ¡†å¤±è´¥ï¼[%1]",
    "Internal error: invalid algorithm type!": "å†…éƒ¨é”™è¯¯ï¼šæ— æ•ˆçš„ç®—æ³•ç±»å‹ï¼",
    "Couldn't allocate a new scalar field for computing fusion labels! Try to free some memory ...": "æ— æ³•åˆ†é…æ–°çš„æ ‡é‡åœºæ¥è®¡ç®—èåˆæ ‡ç­¾ï¼å°è¯•é‡Šæ”¾ä¸€äº›å†…å­˜...",
    " [Kd-tree][error < %1][angle < %2 deg.]": " [Kdæ ‘][è¯¯å·® < %1][è§’åº¦ < %2 åº¦]",
    " [FM][level %2][error < %1]": " [FM][å±‚çº§ %2][è¯¯å·® < %1]",
    "An error occurred during the generation of facets!": "ç”Ÿæˆé¢ç‰‡æ—¶å‘ç”Ÿé”™è¯¯ï¼",
    "An error occurred during the fusion process!": "èåˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼",
    " [facets]": " [é¢ç‰‡]",
    "Couldn't find any facet in the current selection!": "åœ¨å½“å‰é€‰æ‹©ä¸­æ‰¾ä¸åˆ°ä»»ä½•é¢ç‰‡ï¼",
    "An error occurred while classifying the facets! (not enough memory?)": "åˆ†ç±»é¢ç‰‡æ—¶å‘ç”Ÿé”™è¯¯ï¼ï¼ˆå†…å­˜ä¸è¶³ï¼Ÿï¼‰",
    
    # DistanceMapGenerationDlg
    "Map angular step (horizontal)": "åœ°å›¾è§’åº¦æ­¥é•¿ï¼ˆæ°´å¹³ï¼‰",
    "Map height step (vertical)": "åœ°å›¾é«˜åº¦æ­¥é•¿ï¼ˆå‚ç›´ï¼‰",
    "Map heights unit (for display only)": "åœ°å›¾é«˜åº¦å•ä½ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰",
    "m.": "ç±³",
    "What to do when multiple values fall in the same grid cell?": "å½“å¤šä¸ªå€¼è½å…¥åŒä¸€ç½‘æ ¼å•å…ƒæ—¶è¯¥æ€ä¹ˆåŠï¼Ÿ",
    "What to do when a grid cell remains empty?": "å½“ç½‘æ ¼å•å…ƒä¿æŒä¸ºç©ºæ—¶è¯¥æ€ä¹ˆåŠï¼Ÿ",
    " m.": " ç±³",
    "Generatrix direction (in the 3D world)": "æ¯çº¿æ–¹å‘ï¼ˆåœ¨3Dä¸–ç•Œä¸­ï¼‰",
    "Mean radius (for map display, export as a cloud, etc. )": "å¹³å‡åŠå¾„ï¼ˆç”¨äºåœ°å›¾æ˜¾ç¤ºã€å¯¼å‡ºä¸ºç‚¹äº‘ç­‰ï¼‰",
    
    # qCanupoPlugin errors
    "Internal error: failed to access core pointss?!": "å†…éƒ¨é”™è¯¯ï¼šæ— æ³•è®¿é—®æ ¸å¿ƒç‚¹ï¼",
    ".core points (subsampled @ %1)": ".æ ¸å¿ƒç‚¹ï¼ˆé™é‡‡æ ·äº %1ï¼‰",
    "Can't save subsampled cloud (not enough memory)!": "æ— æ³•ä¿å­˜é™é‡‡æ ·ç‚¹äº‘ï¼ˆå†…å­˜ä¸è¶³ï¼‰ï¼",
    "[qCanupo] ": "[qCanupo] ",
    "Internal error: no core point source specified?!": "å†…éƒ¨é”™è¯¯ï¼šæœªæŒ‡å®šæ ¸å¿ƒç‚¹æºï¼",
    "At least one cloud (class #1 or #2) was not defined!": "è‡³å°‘ä¸€ä¸ªç‚¹äº‘ï¼ˆç±»åˆ«#1æˆ–#2ï¼‰æœªå®šä¹‰ï¼",
    "[qCanupo] Some descriptors couldn't be computed on cloud#1 (min scale may be too small)!": "[qCanupo] æŸäº›æè¿°ç¬¦æ— æ³•åœ¨ç‚¹äº‘#1ä¸Šè®¡ç®—ï¼ˆæœ€å°å°ºåº¦å¯èƒ½å¤ªå°ï¼‰ï¼",
    "[qCanupo] Some descriptors couldn't be computed on cloud#2 (min scale may be too small)!": "[qCanupo] æŸäº›æè¿°ç¬¦æ— æ³•åœ¨ç‚¹äº‘#2ä¸Šè®¡ç®—ï¼ˆæœ€å°å°ºåº¦å¯èƒ½å¤ªå°ï¼‰ï¼",
    "[qCanupo] Some descriptors couldn't be computed on evaluation cloud (min scale may be too small)!": "[qCanupo] æŸäº›æè¿°ç¬¦æ— æ³•åœ¨è¯„ä¼°ç‚¹äº‘ä¸Šè®¡ç®—ï¼ˆæœ€å°å°ºåº¦å¯èƒ½å¤ªå°ï¼‰ï¼",
    
    # GeomFeaturesDialog - Technical formulas
    "Number of neighbors / neighborhood area": "é‚»åŸŸæ•°é‡ / é‚»åŸŸé¢ç§¯",
    "Number of neighbors / neighborhood volume": "é‚»åŸŸæ•°é‡ / é‚»åŸŸä½“ç§¯",
    "Geometric features (based on local eigenvalues: (L1, L2, L3))": "å‡ ä½•ç‰¹å¾ï¼ˆåŸºäºå±€éƒ¨ç‰¹å¾å€¼ï¼š(L1, L2, L3)ï¼‰",
    "(L1 * L2 * L3)^(1/3)": "(L1 * L2 * L3)^(1/3)",
    "-( L1*ln(L1) + L2*ln(L2) + L3*ln(L3) )": "-( L1*ln(L1) + L2*ln(L2) + L3*ln(L3) )",
    "(L1 - L3)/L1": "(L1 - L3)/L1",
    "(L2 - L3)/L1": "(L2 - L3)/L1",
    "(L1 - L2)/L1": "(L1 - L2)/L1",
    
    # RegistrationDialog - Long descriptions
    "the data cloud is the entity to align with the model cloud : it will be displaced (red cloud)": "æ•°æ®ç‚¹äº‘æ˜¯è¦ä¸æ¨¡å‹ç‚¹äº‘å¯¹é½çš„å®ä½“ï¼šå®ƒå°†è¢«ç§»åŠ¨ï¼ˆçº¢è‰²ç‚¹äº‘ï¼‰",
    "the model cloud is the reference : it won't move (yellow cloud)": "æ¨¡å‹ç‚¹äº‘æ˜¯å‚è€ƒï¼šå®ƒä¸ä¼šç§»åŠ¨ï¼ˆé»„è‰²ç‚¹äº‘ï¼‰",
    "By choosing this criterion, you can control the computation time.": "é€šè¿‡é€‰æ‹©æ­¤æ ‡å‡†ï¼Œæ‚¨å¯ä»¥æ§åˆ¶è®¡ç®—æ—¶é—´ã€‚",
    "By choosing this criterion, you can control the quality of the result.": "é€šè¿‡é€‰æ‹©æ­¤æ ‡å‡†ï¼Œæ‚¨å¯ä»¥æ§åˆ¶ç»“æœçš„è´¨é‡ã€‚",
    "Rough estimation of the final overlap ratio of the data cloud (the smaller, the better the initial registration should be)": "æ•°æ®ç‚¹äº‘æœ€ç»ˆé‡å æ¯”çš„ç²—ç•¥ä¼°è®¡ï¼ˆè¶Šå°ï¼Œåˆå§‹é…å‡†åº”è¯¥è¶Šå¥½ï¼‰",
    "Whether to adjust the scale of the 'data' entity": "æ˜¯å¦è°ƒæ•´'æ•°æ®'å®ä½“çš„æ¯”ä¾‹",
    "Chose this option to remove points that are likely to disturb the registration during the computation (that do not belong to any plane)": "é€‰æ‹©æ­¤é€‰é¡¹ä»¥ç§»é™¤å¯èƒ½åœ¨è®¡ç®—æœŸé—´å¹²æ‰°é…å‡†çš„ç‚¹ï¼ˆä¸å±äºä»»ä½•å¹³é¢çš„ç‚¹ï¼‰",
    
    # GreedyTriangulation
    "Greedy Triangulation from clouds": "è´ªå©ªä¸‰è§’åŒ–ï¼ˆä»ç‚¹äº‘ï¼‰",
    "[GreedyTriangulation::compute] generate new normals": "[è´ªå©ªä¸‰è§’åŒ–::è®¡ç®—] ç”Ÿæˆæ–°æ³•çº¿",
    "[GreedyTriangulation::compute] find normals and use the normals": "[è´ªå©ªä¸‰è§’åŒ–::è®¡ç®—] æŸ¥æ‰¾å¹¶ä½¿ç”¨æ³•çº¿",
    "[greedy-triangulation-Reconstruction] %1 points, %2 face(s)": "[è´ªå©ªä¸‰è§’åŒ–-é‡å»º] %1 ä¸ªç‚¹ï¼Œ%2 ä¸ªé¢",
    "Greedy Triangulation does not returned any point. Try relaxing your parameters": "è´ªå©ªä¸‰è§’åŒ–æœªè¿”å›ä»»ä½•ç‚¹ã€‚å°è¯•æ”¾å®½å‚æ•°",
    
    # MatchScalesDialog
    "The scaling ratio will be deduced from the largest bounding-box dimension": "ç¼©æ”¾æ¯”å°†ä»æœ€å¤§åŒ…å›´ç›’ç»´åº¦æ¨å¯¼",
    "The scaling ratio will be deduced from the bounding-box volume": "ç¼©æ”¾æ¯”å°†ä»åŒ…å›´ç›’ä½“ç§¯æ¨å¯¼",
    "The scaling ratio will be deduced from the principal cloud dimension (by PCA analysis)": "ç¼©æ”¾æ¯”å°†ä»ä¸»ç‚¹äº‘ç»´åº¦æ¨å¯¼ï¼ˆé€šè¿‡PCAåˆ†æï¼‰",
    "The scaling ratio will be deduced from automatic registration (with unconstrained scale). Should be used only with very similar entities!": "ç¼©æ”¾æ¯”å°†ä»è‡ªåŠ¨é…å‡†æ¨å¯¼ï¼ˆä¸å—é™åˆ¶çš„æ¯”ä¾‹ï¼‰ã€‚åº”ä»…ç”¨äºéå¸¸ç›¸ä¼¼çš„å®ä½“ï¼",
    "Rough estimation of the final overlap ratio of the data cloud (the smaller, the better the initial registration should be)": "æ•°æ®ç‚¹äº‘æœ€ç»ˆé‡å æ¯”çš„ç²—ç•¥ä¼°è®¡ï¼ˆè¶Šå°ï¼Œåˆå§‹é…å‡†åº”è¯¥è¶Šå¥½ï¼‰",
    
    # PoissonReconParamDialog
    "The maximum depth of the tree that will be used for surface reconstruction": "ç”¨äºè¡¨é¢é‡å»ºçš„æ ‘çš„æœ€å¤§æ·±åº¦",
    "If this flag is enabled, the sampling density is output as a scalar field": "å¦‚æœå¯ç”¨æ­¤æ ‡å¿—ï¼Œé‡‡æ ·å¯†åº¦å°†ä½œä¸ºæ ‡é‡åœºè¾“å‡º",
    
    # More MainWindow messages
    "Entity '%1' has its coordinate center still shifted": "å®ä½“ '%1' çš„åæ ‡ä¸­å¿ƒä»æœ‰åç§»",
    "Shift on loading: (%1;%2;%3)": "åŠ è½½æ—¶çš„åç§»ï¼š(%1;%2;%3)",
    "Shift on input: (%1;%2;%3)": "è¾“å…¥æ—¶çš„åç§»ï¼š(%1;%2;%3)",
    "Entity is too big to be correctly displayed": "å®ä½“å¤ªå¤§ï¼Œæ— æ³•æ­£ç¡®æ˜¾ç¤º",
    "To reduce display shifts and artifacts, you can apply a global shift": "ä¸ºå‡å°‘æ˜¾ç¤ºåç§»å’Œä¼ªå½±ï¼Œæ‚¨å¯ä»¥åº”ç”¨å…¨å±€åç§»",
    "Global shift has been defined by user": "å…¨å±€åç§»å·²ç”±ç”¨æˆ·å®šä¹‰",
    "Global shift has been defined automatically": "å…¨å±€åç§»å·²è‡ªåŠ¨å®šä¹‰",
    
    # More QObject messages
    "Invalid parameter: %1": "æ— æ•ˆå‚æ•°ï¼š%1",
    "Invalid command: %1": "æ— æ•ˆå‘½ä»¤ï¼š%1",
    "Command '%1' requires at least %2 argument(s)": "å‘½ä»¤ '%1' éœ€è¦è‡³å°‘ %2 ä¸ªå‚æ•°",
    "Command '%1' requires exactly %2 argument(s)": "å‘½ä»¤ '%1' éœ€è¦ç¡®åˆ‡ %2 ä¸ªå‚æ•°",
    "Unknown file extension: %1": "æœªçŸ¥æ–‡ä»¶æ‰©å±•åï¼š%1",
    "File not found: %1": "æ–‡ä»¶æœªæ‰¾åˆ°ï¼š%1",
    "Failed to load file: %1": "åŠ è½½æ–‡ä»¶å¤±è´¥ï¼š%1",
    "Failed to save file: %1": "ä¿å­˜æ–‡ä»¶å¤±è´¥ï¼š%1",
    "Operation cancelled by user": "æ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ",
    "Processing...": "å¤„ç†ä¸­...",
    "Initializing...": "åˆå§‹åŒ–ä¸­...",
    "Finalizing...": "å®Œæˆä¸­...",
}

def translate_ts_file_round3(input_file, output_file):
    """Round 3 translation - final push to 100%"""
    
    tree = ET.parse(input_file)
    root = tree.getroot()
    
    translated_count = 0
    final_untranslated = []
    
    for context in root.findall('.//context'):
        context_name = context.find('name').text if context.find('name') is not None else "Unknown"
        
        for message in context.findall('message'):
            translation = message.find('translation')
            if translation is None:
                continue
            
            trans_type = translation.get('type', '')
            if trans_type != 'unfinished' and translation.text:
                continue
            
            source = message.find('source')
            if source is None or not source.text:
                continue
            
            source_text = source.text
            
            if source_text in ROUND3_TRANSLATIONS:
                translation.text = ROUND3_TRANSLATIONS[source_text]
                if 'type' in translation.attrib:
                    del translation.attrib['type']
                translated_count += 1
            else:
                final_untranslated.append({
                    'context': context_name,
                    'source': source_text
                })
    
    # Write output
    tree.write(output_file, encoding='utf-8', xml_declaration=True)
    
    # Save final untranslated
    if final_untranslated:
        with open('/home/ludahai/develop/code/github/ACloudViewer/eCV/translations/scripts/final_untranslated.txt',
                  'w', encoding='utf-8') as f:
            f.write(f"æœ€ç»ˆå¾…äººå·¥ç¿»è¯‘å†…å®¹ ({len(final_untranslated)} æ¡)\n")
            f.write(f"{'='*80}\n\n")
            
            from collections import defaultdict
            by_context = defaultdict(list)
            for item in final_untranslated:
                by_context[item['context']].append(item['source'])
            
            for ctx, items in sorted(by_context.items(), key=lambda x: len(x[1]), reverse=True):
                f.write(f"\n{ctx} ({len(items)} æ¡)\n")
                f.write(f"{'-'*80}\n")
                for i, source in enumerate(items, 1):
                    f.write(f"{i}. {source}\n\n")
    
    print(f"\n{'='*80}")
    print(f"ç¬¬3è½®ç¿»è¯‘å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"æœ¬æ¬¡ç¿»è¯‘: {translated_count} æ¡")
    print(f"æœ€ç»ˆå‰©ä½™: {len(final_untranslated)} æ¡")
    if final_untranslated:
        print(f"è¯¦ç»†åˆ—è¡¨: scripts/final_untranslated.txt")
    print(f"{'='*80}\n")
    
    return translated_count, len(final_untranslated)

if __name__ == "__main__":
    input_file = '/home/ludahai/develop/code/github/ACloudViewer/eCV/translations/ACloudViewer_zh.ts'
    output_file = input_file
    
    translated, remaining = translate_ts_file_round3(input_file, output_file)
    
    print(f"âœ“ ç¬¬3è½®æˆåŠŸç¿»è¯‘ {translated} æ¡")
    if remaining > 0:
        print(f"! è¿˜æœ‰ {remaining} æ¡éœ€è¦äººå·¥ç²¾ç»†ç¿»è¯‘ï¼ˆé€šå¸¸æ˜¯éå¸¸ç‰¹æ®Šçš„æŠ€æœ¯å†…å®¹æˆ–æ ¼å¼é—®é¢˜ï¼‰")
        print(f"  å»ºè®®ä½¿ç”¨Qt Linguisté€ä¸ªå¤„ç†")
    else:
        print(f"ğŸ‰ğŸ‰ğŸ‰ 100%è¦†ç›–ç‡è¾¾æˆï¼æ‰€æœ‰å†…å®¹å·²ç¿»è¯‘å®Œæˆï¼")
