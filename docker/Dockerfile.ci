# FROM must be called before other ARGS except for ARG BASE_IMAGE
ARG BASE_IMAGE
FROM ${BASE_IMAGE}

# For bash-specific commands
SHELL ["/bin/bash", "-c"]

# Required build args, should be specified in docker_build.sh
ARG DEVELOPER_BUILD
ARG CCACHE_TAR_NAME
ARG CMAKE_VERSION
ARG CCACHE_VERSION
ARG PYTHON_VERSION
ARG BUILD_SHARED_LIBS
ARG BUILD_CUDA_MODULE
ARG BUILD_TENSORFLOW_OPS
ARG BUILD_PYTORCH_OPS
ARG PACKAGE
ARG BUILD_GUI
ARG BUILD_WHEEL
ARG CI

RUN if [ -z "${DEVELOPER_BUILD}"      ]; then echo "Error: ARG DEVELOPER_BUILD      not specified."; exit 1; fi \
 && if [ -z "${CCACHE_TAR_NAME}"      ]; then echo "Error: ARG CCACHE_TAR_NAME      not specified."; exit 1; fi \
 && if [ -z "${CMAKE_VERSION}"        ]; then echo "Error: ARG CMAKE_VERSION        not specified."; exit 1; fi \
 && if [ -z "${CCACHE_VERSION}"       ]; then echo "Error: ARG CCACHE_VERSION       not specified."; exit 1; fi \
 && if [ -z "${PYTHON_VERSION}"       ]; then echo "Error: ARG PYTHON_VERSION       not specified."; exit 1; fi \
 && if [ -z "${BUILD_SHARED_LIBS}"    ]; then echo "Error: ARG BUILD_SHARED_LIBS    not specified."; exit 1; fi \
 && if [ -z "${BUILD_CUDA_MODULE}"    ]; then echo "Error: ARG BUILD_CUDA_MODULE    not specified."; exit 1; fi \
 && if [ -z "${BUILD_TENSORFLOW_OPS}" ]; then echo "Error: ARG BUILD_TENSORFLOW_OPS not specified."; exit 1; fi \
 && if [ -z "${BUILD_PYTORCH_OPS}"    ]; then echo "Error: ARG BUILD_PYTORCH_OPS    not specified."; exit 1; fi \
 && if [ -z "${PACKAGE}"              ]; then echo "Error: ARG PACKAGE              not specified."; exit 1; fi 

# Fix Nvidia repo key rotation issue
# https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212771
# https://forums.developer.nvidia.com/t/18-04-cuda-docker-image-is-broken/212892/10
# https://code.visualstudio.com/remote/advancedcontainers/reduce-docker-warnings#:~:text=Warning%3A%20apt%2Dkey%20output%20should,not%20running%20from%20a%20terminal.
RUN if [ "${BUILD_CUDA_MODULE}" = "ON" ]; then \
        export APT_KEY_DONT_WARN_ON_DANGEROUS_USAGE=DontWarn; \
        apt-key del 7fa2af80; \
        apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub; \
        apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub; \
    fi

# Forward all ARG to ENV
# ci_utils.sh may require these environment variables
ENV DEVELOPER_BUILD=${DEVELOPER_BUILD}
ENV CCACHE_TAR_NAME=${CCACHE_TAR_NAME}
ENV CMAKE_VERSION=${CMAKE_VERSION}
ENV CCACHE_VERSION=${CCACHE_VERSION}
ENV PYTHON_VERSION=${PYTHON_VERSION}
ENV BUILD_SHARED_LIBS=OFF
ENV BUILD_CUDA_MODULE=${BUILD_CUDA_MODULE}
ENV BUILD_TENSORFLOW_OPS=${BUILD_TENSORFLOW_OPS}
ENV BUILD_PYTORCH_OPS=${BUILD_PYTORCH_OPS}
ENV PACKAGE=${PACKAGE}
ENV BUILD_WHEEL=${BUILD_WHEEL}
ENV BUILD_GUI=${BUILD_GUI}

# Prevent interactive inputs when installing packages
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=America/Los_Angeles
ENV SUDO=command

# Env vars for the nvidia-container-runtime.
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES all

# Update apt and install libs needed by Qt
RUN apt-get clean && apt-get update --fix-missing -y \
    && apt-get install apt-utils software-properties-common tzdata --fix-missing -y \
    && apt-key adv --fetch-keys https://apt.kitware.com/keys/kitware-archive-latest.asc \
    && apt-add-repository --yes "deb https://apt.kitware.com/ubuntu/ $(lsb_release -c --short) main" \
    && apt-get update --fix-missing -y \
    && apt-get install --fix-missing -yq --no-install-recommends \
        build-essential \
        git  \
        cmake \
        wget \
        curl \
        vim \
        tree \
        apt-file \
        net-tools \
        mesa-utils \
        # for opencv
        libjpeg-dev \
        libpng-dev \
        libtiff-dev \
        # for colmap
        libatlas-base-dev \
        # for package
        zip \
        unzip \
        locate \
        automake \
        xorg-dev \
        libxi-dev \
        openmpi-bin \
        openmpi-common \
        gfortran \
        ninja-build \
        libgtest-dev \
        libusb-dev \
        freeglut3-dev \
        pkg-config \
        libpcap-dev \
        clang-format \
        graphviz \
        nasm \
        flex \
        fontconfig \
        # libgdal-dev \
        # libcgal-dev \
        # for QT
        libxcb-xkb1 \
        libxcb-shape0 \
        libxcb-randr0 \
        libxcb-icccm4 \
        libxcb-image0 \
        libxcb-keysyms1 \
        libxcb-xinerama0 \
        libxkbcommon-x11-0 \
        libxcb-render-util0


# Dependencies: basic
RUN apt-get update && apt-get install -y \
    git  \
    wget \
    curl \
    build-essential \
    pkg-config \
 && rm -rf /var/lib/apt/lists/*

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

 # Miniconda or Intel conda
# The **/cloudViewer/bin paths are used during docker run, in this way docker run
# does not need to activate the environment again.
ENV PATH="/root/miniconda3/bin:${PATH}"
ENV PATH="/opt/intel/oneapi/intelpython/latest/bin:${PATH}"
ENV PATH="/opt/intel/oneapi/intelpython/latest/envs/cloudViewer/bin:${PATH}"
RUN wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \
 && bash Miniconda3-latest-Linux-x86_64.sh -b \
 && rm Miniconda3-latest-Linux-x86_64.sh \
 && conda --version

# deploy package installer
WORKDIR /root
RUN wget https://raw.githubusercontent.com/Asher-1/CloudViewerUpdate/main/tools/QtIFW-4.6.1-linux-amd.zip -O "/root/QtIFW-4.6.1-linux-amd.zip"
RUN unzip QtIFW-4.6.1-linux-amd.zip && rm -rf QtIFW-4.6.1-linux-amd.zip
ENV PATH="/root/QtIFW-4.6.1-linux-amd/bin:$PATH"

# Checkout CloudViewer-ML main branch
# TODO: We may add support for local CloudViewer-ML repo or pinned ML repo tag
ENV ACloudViewer_DEV=/root \
    ACloudViewer_BUILD=/root/ACloudViewer/build \
    ACloudViewer_INSTALL=/root/install

# Checkout CloudViewer-ML main branch
# TODO: We may add support for local CloudViewer-ML repo or pinned ML repo tag
ENV CLOUDVIEWER_ML_ROOT=/root/CloudViewer-ML
RUN git clone --depth 1 https://github.com/Asher-1/CloudViewer-ML.git ${CLOUDVIEWER_ML_ROOT}

ENV PATH="/root/miniconda3/bin:$PATH" \
    CONDA_EXE="/root/miniconda3/bin/conda"

RUN if [ -n "$CONDA_EXE" ]; then \
        CONDA_ROOT=$(dirname $(dirname "$CONDA_EXE")); \
    elif [ -n "$CONDA_PREFIX" ]; then \
        CONDA_ROOT=$(dirname "$CONDA_PREFIX"); \
    else \
        echo "Failed to find Miniconda3 install path..."; \
        exit 1; \
    fi && \
    echo "CONDA_ROOT is set to: $CONDA_ROOT" && \
    source "$CONDA_ROOT/etc/profile.d/conda.sh" 

# ACloudViewer repo
# Always keep /root/ACloudViewer as the WORKDIR
COPY . ${ACloudViewer_DEV}/ACloudViewer
WORKDIR ${ACloudViewer_DEV}/ACloudViewer

# ACloudViewer C++ dependencies
RUN ./util/install_deps_ubuntu.sh assume-yes

# ACloudViewer Jupyter dependencies
RUN mkdir -p /etc/apt/keyrings \
 && curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key \
 | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg \
 && echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x nodistro main" \
 | tee /etc/apt/sources.list.d/nodesource.list \
 && apt-get update \
 && apt-get install -y nodejs \
 && rm -rf /var/lib/apt/lists/* \
 && node --version \
 && npm install -g yarn \
 && yarn --version


RUN mkdir -p ${ACloudViewer_INSTALL}

# Build ACloudViewer app installer
RUN if [ "${BUILD_GUI}" = "ON" ]; then                              \
        echo "Start Build ACloudViewer apps installer..." &&        \
        rm -rf ${ACloudViewer_BUILD}/* &&                           \
        ./docker/build_gui_app_conda.sh ${PYTHON_VERSION};          \
        rm -rf ${ACloudViewer_BUILD}/*;                             \
    fi

RUN if [ "${BUILD_WHEEL}" = "ON" ]; then                            \
        echo "Build cloudViewer wheel for ${PYTHON_VERSION}..." &&  \
        rm -rf ${ACloudViewer_BUILD}/* &&                           \
        ./docker/build_cloudviewer_whl_conda.sh ${PYTHON_VERSION};  \
        rm -rf ${ACloudViewer_BUILD}/*;                             \
    fi
    
WORKDIR ${ACloudViewer_DEV}/ACloudViewer

RUN echo "Docker build done."
